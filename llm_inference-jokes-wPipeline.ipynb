{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-28T14:32:53.476576Z","iopub.status.busy":"2024-05-28T14:32:53.475920Z","iopub.status.idle":"2024-05-28T14:34:16.126198Z","shell.execute_reply":"2024-05-28T14:34:16.125030Z","shell.execute_reply.started":"2024-05-28T14:32:53.476547Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/envs/pytorch/lib/python3.10/site-packages (4.41.1)\n","Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (0.23.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (2.32.1)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: datasets in /opt/conda/envs/pytorch/lib/python3.10/site-packages (2.19.1)\n","Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (3.14.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (16.1.0)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (2.32.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (4.66.4)\n","Requirement already satisfied: xxhash in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\n","Requirement already satisfied: aiohttp in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (0.23.2)\n","Requirement already satisfied: packaging in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: bitsandbytes in /opt/conda/envs/pytorch/lib/python3.10/site-packages (0.43.1)\n","Requirement already satisfied: torch in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from bitsandbytes) (2.2.0)\n","Requirement already satisfied: numpy in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->bitsandbytes) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->bitsandbytes) (4.11.0)\n","Requirement already satisfied: sympy in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\n","Requirement already satisfied: fsspec in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: huggingface_hub in /opt/conda/envs/pytorch/lib/python3.10/site-packages (0.23.2)\n","Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface_hub) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface_hub) (2024.3.1)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface_hub) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface_hub) (2.32.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface_hub) (4.11.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: codecarbon in /opt/conda/envs/pytorch/lib/python3.10/site-packages (2.4.2)\n","Requirement already satisfied: arrow in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from codecarbon) (1.3.0)\n","Requirement already satisfied: click in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from codecarbon) (8.1.7)\n","Requirement already satisfied: pandas in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from codecarbon) (2.2.2)\n","Requirement already satisfied: prometheus-client in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from codecarbon) (0.20.0)\n","Requirement already satisfied: psutil in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from codecarbon) (5.9.8)\n","Requirement already satisfied: py-cpuinfo in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from codecarbon) (9.0.0)\n","Requirement already satisfied: pynvml in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from codecarbon) (11.5.0)\n","Requirement already satisfied: rapidfuzz in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from codecarbon) (3.9.1)\n","Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from codecarbon) (2.32.1)\n","Requirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from arrow->codecarbon) (2.9.0)\n","Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from arrow->codecarbon) (2.9.0.20240316)\n","Requirement already satisfied: numpy>=1.22.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->codecarbon) (1.26.4)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->codecarbon) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->codecarbon) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->codecarbon) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->codecarbon) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->codecarbon) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->codecarbon) (2024.2.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: ipywidgets in /opt/conda/envs/pytorch/lib/python3.10/site-packages (8.1.3)\n","Requirement already satisfied: comm>=0.1.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n","Requirement already satisfied: ipython>=6.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipywidgets) (8.21.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\n","Requirement already satisfied: widgetsnbextension~=4.0.11 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipywidgets) (4.0.11)\n","Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipywidgets) (3.0.11)\n","Requirement already satisfied: decorator in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n","Requirement already satisfied: matplotlib-inline in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n","Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.42)\n","Requirement already satisfied: pygments>=2.4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n","Requirement already satisfied: stack-data in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n","Requirement already satisfied: exceptiongroup in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n","Requirement already satisfied: pexpect>4.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n","Requirement already satisfied: wcwidth in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n","Requirement already satisfied: executing>=1.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n","Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n","Requirement already satisfied: pure-eval in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: accelerate in /opt/conda/envs/pytorch/lib/python3.10/site-packages (0.30.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from accelerate) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from accelerate) (5.9.8)\n","Requirement already satisfied: pyyaml in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from accelerate) (2.2.0)\n","Requirement already satisfied: huggingface-hub in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from accelerate) (0.23.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\n","Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n","Requirement already satisfied: sympy in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: fsspec in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n","Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["#%pip install -U torch\n","#%pip install -U pandas\n","#%pip install -U matplotlib\n","#%pip install -U seaborn\n","#%pip install -U trl\n","#%pip install -U numpy\n","#%pip install -U peft\n","%pip install -U transformers\n","%pip install -U datasets\n","%pip install -U bitsandbytes #==0.41.1\n","%pip install -U huggingface_hub\n","#%pip install -U tqdm\n","%pip install -U codecarbon\n","%pip install -U ipywidgets\n","%pip install -U accelerate"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:08:38.065871Z","iopub.status.busy":"2024-05-28T15:08:38.065401Z","iopub.status.idle":"2024-05-28T15:08:38.071563Z","shell.execute_reply":"2024-05-28T15:08:38.070616Z","shell.execute_reply.started":"2024-05-28T15:08:38.065841Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch\n","import accelerate\n","from accelerate import infer_auto_device_map\n","#from datasets import load_dataset, Dataset\n","#from scipy.special import softmax\n","#from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n","#from sklearn.metrics import accuracy_score, f1_score, log_loss, confusion_matrix\n","from transformers import  AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n","from huggingface_hub import notebook_login, login\n","#import json\n","import pandas as pd\n","import os\n","#from tqdm import tqdm\n","#import random\n","from codecarbon import EmissionsTracker, track_emissions\n","from time import time\n","import csv"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T14:34:21.991798Z","iopub.status.busy":"2024-05-28T14:34:21.991297Z","iopub.status.idle":"2024-05-28T14:34:22.050360Z","shell.execute_reply":"2024-05-28T14:34:22.049314Z","shell.execute_reply.started":"2024-05-28T14:34:21.991768Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# Check if GPUs are available and move model to GPUs\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T14:34:22.053188Z","iopub.status.busy":"2024-05-28T14:34:22.052936Z","iopub.status.idle":"2024-05-28T14:34:22.066843Z","shell.execute_reply":"2024-05-28T14:34:22.066083Z","shell.execute_reply.started":"2024-05-28T14:34:22.053166Z"},"trusted":true},"outputs":[],"source":["#model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n","model_name = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n","#model_name = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n","\n","#model_name = 'meta-llama/Meta-Llama-3-8B'\n","#model_name = 'meta-llama/Llama-2-7b-chat-hf'\n","#model_name = 'meta-llama/Llama-2-13b-chat-hf'\n","#model_name = 'meta-llama/Llama-2-70b-chat-hf'\n","#model_name = \"/kaggle/input/llama-3/transformers/8b-hf/1\"\n","\n","#model_name = \"unsloth/llama-3-70b-bnb-4bit\"\n","\n","#save_path = f\"models/{model_name}\"\n","#print(f\"Saving model to / Loading model from:\\n\\n -> {save_path}\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T14:34:22.068139Z","iopub.status.busy":"2024-05-28T14:34:22.067896Z","iopub.status.idle":"2024-05-28T14:34:22.076019Z","shell.execute_reply":"2024-05-28T14:34:22.075175Z","shell.execute_reply.started":"2024-05-28T14:34:22.068117Z"},"trusted":true},"outputs":[],"source":["#quantization configurations - so you quantize the model while inferencing\n","bnb_config = BitsAndBytesConfig(\n","    #load_in_4bit = True,\n","    load_in_8bit=True,\n","    llm_int8_skip_modules=[\"lm_head\"],\n","    #llm_int8_threshold=4.0,\n","    #llm_int8_has_fp16_weight=True,\n","    #bnb_4bit_qunat_type = \"nf4\",\n","    #bnb_4bit_compute_dtype = torch.float16,\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T14:34:22.077729Z","iopub.status.busy":"2024-05-28T14:34:22.077168Z","iopub.status.idle":"2024-05-28T14:34:22.084008Z","shell.execute_reply":"2024-05-28T14:34:22.083252Z","shell.execute_reply.started":"2024-05-28T14:34:22.077698Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /home/ubuntu/.cache/huggingface/token\n","Login successful\n"]}],"source":["login(token=\"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\")\n","#notebook_login()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#device_map = infer_auto_device_map(model, max_memory={0: \"20GiB\", 1: \"20GiB\", 2: \"20GiB\", 3: \"20GiB\", \"cpu\": \"100GiB\"})"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T14:34:22.085324Z","iopub.status.busy":"2024-05-28T14:34:22.085052Z","iopub.status.idle":"2024-05-28T14:36:09.831820Z","shell.execute_reply":"2024-05-28T14:36:09.830985Z","shell.execute_reply.started":"2024-05-28T14:34:22.085294Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb17bc3dbb8d4eb393373533b6b15fb0","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Load the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.pad_token = tokenizer.bos_token\n","\n","# Load the model\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    #load_in_8bit=True,\n","    #model_path,\n","    #num_labels=4,  # Adjust if necessary based on the specific task\n","    quantization_config=bnb_config,\n","    #device_map=\"auto\",\n","    device_map=\"sequential\",\n","    #torch_dtype=torch.float16,\n","    #device_map=device_map,\n","    #load_in_8bit_fp32_cpu_offload=True,\n",")\n","model.config.pad_token_id = tokenizer.pad_token_id"]},{"cell_type":"markdown","metadata":{},"source":["# Test the Model"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T14:36:09.833289Z","iopub.status.busy":"2024-05-28T14:36:09.832879Z","iopub.status.idle":"2024-05-28T14:36:09.839082Z","shell.execute_reply":"2024-05-28T14:36:09.838108Z","shell.execute_reply.started":"2024-05-28T14:36:09.833264Z"},"trusted":true},"outputs":[],"source":["# List of words that should be used to create sentences.\n","\n","words = [\n","    \"apple\", \"book\", \"car\", \"dog\", \"elephant\", \"forest\", \"guitar\", \"house\", \n","    \"island\", \"jacket\", \"kangaroo\", \"lamp\", \"mountain\", \"notebook\", \"ocean\", \n","    \"pencil\", \"queen\", \"river\", \"star\", \"tree\", \"umbrella\", \"village\", \n","    \"window\", \"xylophone\", \"yacht\", \"zebra\", \"balloon\", \"camera\", \"desert\", \n","    \"engine\", \"flower\", \"garden\", \"honey\", \"iceberg\", \"jungle\", \"kite\", \n","    \"ladder\", \"moon\", \"nest\", \"octopus\", \"pirate\", \"quilt\", \"robot\", \"swan\", \n","    \"telescope\", \"unicorn\", \"violin\", \"whale\", \"x-ray\", \"laptop\"\n","]"]},{"cell_type":"markdown","metadata":{},"source":["# Approach with Pipeline"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T15:03:23.481846Z","iopub.status.busy":"2024-05-28T15:03:23.481083Z","iopub.status.idle":"2024-05-28T15:03:23.486359Z","shell.execute_reply":"2024-05-28T15:03:23.485531Z","shell.execute_reply.started":"2024-05-28T15:03:23.481807Z"},"trusted":true},"outputs":[],"source":["# Initialize the pipeline\n","text_generation_pipeline = pipeline('text-generation', model=model, tokenizer=tokenizer, device_map=\"auto\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T16:22:58.058744Z","iopub.status.busy":"2024-05-28T16:22:58.057871Z","iopub.status.idle":"2024-05-28T16:22:58.068148Z","shell.execute_reply":"2024-05-28T16:22:58.067150Z","shell.execute_reply.started":"2024-05-28T16:22:58.058711Z"},"trusted":true},"outputs":[],"source":["def query_model(word, temperature=0.6, max_length=48):\n","    start_time = time()\n","    \n","    system_message = f\"\"\"\n","    You are an AI assistant designed to tell jokes for a given word.\n","    Generate a short joke that is exactly 2 short sentences long. Do not include any follow-up questions or explanations.\n","\n","    For example, a joke for the word \"yogurt\":\n","    'Why did the yogurt go to the art gallery? Because it wanted to be cultured!'\n","\n","    Be as close as possible to the example joke!\n","    Respond with only the joke itself. Do not include any introductory phrases.\n","\n","    \"\"\"\n","    \n","    user_message = \"Question: \" + f'Now, tell me one short joke for the word: \"{word}\"\\n' + \" Answer:\"\n","    \n","    messages = [\n","        {\"role\": \"system\", \"content\": system_message},\n","        {\"role\": \"user\", \"content\": user_message},\n","    ]\n","    prompt = tokenizer.apply_chat_template(\n","        messages, \n","        tokenize=False, \n","        add_generation_prompt=True\n","    )\n","    \n","    # Tokenize the prompt to count input tokens\n","    input_tokens = tokenizer.encode(prompt)\n","    input_token_count = len(input_tokens)\n","    \n","    terminators = [\n","        tokenizer.eos_token_id,\n","        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n","    ]\n","    sequences = text_generation_pipeline(\n","        prompt,\n","        do_sample=True,\n","        top_p=0.9,\n","        temperature=temperature,\n","        eos_token_id=terminators,\n","        max_new_tokens=max_length,\n","        return_full_text=False,\n","        pad_token_id=model.config.eos_token_id\n","    )\n","    answer = sequences[0]['generated_text']\n","    \n","    # Tokenize the answer to count output tokens\n","    output_tokens = tokenizer.encode(answer)\n","    output_token_count = len(output_tokens)\n","    \n","    end_time = time()\n","    ttime = f\"Total time: {round(end_time-start_time, 2)} sec.\"\n","\n","    return (\n","        user_message + \"\\n\\n\" + answer + \"\\n\\n\" + ttime,\n","        input_token_count,\n","        output_token_count\n","    )"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T16:37:32.187584Z","iopub.status.busy":"2024-05-28T16:37:32.186903Z","iopub.status.idle":"2024-05-28T16:54:12.587373Z","shell.execute_reply":"2024-05-28T16:54:12.586363Z","shell.execute_reply.started":"2024-05-28T16:37:32.187554Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["==================== INFERENCE TEST ====================\n","\n","\n","      Starting Test with 2 Runs and 50 Words/Run. \n","\n","      Total Prompts: 100\n","\n","\n","      Expected Runtime: 33.333333333333336min \n","\n","      Expected Input Tokens: 10300 \n","\n","      Expected Output Tokens: 3000 \n","\n","\n","      \n","========================= Run 1 =========================\n","\n","\n","------------------------- Word 1 -------------------------\n","Question: Now, tell me one short joke for the word: \"apple\"\n"," Answer:\n","\n","Why did the apple join the gym? To get some core strength!\n","\n","Total time: 8.38 sec.\n","\n","\n","Input tokens: 132, Output tokens: 15\n","\n","\n","------------------------- Word 2 -------------------------\n","Question: Now, tell me one short joke for the word: \"book\"\n"," Answer:\n","\n","Why did the book go to the party? Because it was a real page-turner!\n","\n","Total time: 8.8 sec.\n","\n","\n","Input tokens: 132, Output tokens: 19\n","\n","\n","------------------------- Word 3 -------------------------\n","Question: Now, tell me one short joke for the word: \"car\"\n"," Answer:\n","\n","Why did the car go to the doctor? It was feeling a little \"car\"-sick!\n","\n","Total time: 9.6 sec.\n","\n","\n","Input tokens: 132, Output tokens: 21\n","\n","\n","------------------------- Word 4 -------------------------\n","Question: Now, tell me one short joke for the word: \"dog\"\n"," Answer:\n","\n","Why did the dog go to the vet? Because it was feeling ruff!\n","\n","Total time: 7.95 sec.\n","\n","\n","Input tokens: 132, Output tokens: 17\n","\n","\n","------------------------- Word 5 -------------------------\n","Question: Now, tell me one short joke for the word: \"elephant\"\n"," Answer:\n","\n","Why did the elephant quit the circus? Because it was tired of working for peanuts!\n","\n","Total time: 8.43 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 6 -------------------------\n","Question: Now, tell me one short joke for the word: \"forest\"\n"," Answer:\n","\n","Why did the tree go to the party in the forest? Because it wanted to branch out!\n","\n","Total time: 9.35 sec.\n","\n","\n","Input tokens: 132, Output tokens: 20\n","\n","\n","------------------------- Word 7 -------------------------\n","Question: Now, tell me one short joke for the word: \"guitar\"\n"," Answer:\n","\n","Why was the guitar sad? Because it was out of tune!\n","\n","Total time: 6.63 sec.\n","\n","\n","Input tokens: 133, Output tokens: 14\n","\n","\n","------------------------- Word 8 -------------------------\n","Question: Now, tell me one short joke for the word: \"house\"\n"," Answer:\n","\n","Why did the house go to therapy? Because it had a lot of \"foundation\" issues!\n","\n","Total time: 9.2 sec.\n","\n","\n","Input tokens: 132, Output tokens: 20\n","\n","\n","------------------------- Word 9 -------------------------\n","Question: Now, tell me one short joke for the word: \"island\"\n"," Answer:\n","\n","Why did the island go to therapy? Because it was feeling a little isolated!\n","\n","Total time: 7.88 sec.\n","\n","\n","Input tokens: 133, Output tokens: 17\n","\n","\n","------------------------- Word 10 -------------------------\n"]},{"name":"stderr","output_type":"stream","text":["You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"]},{"name":"stdout","output_type":"stream","text":["Question: Now, tell me one short joke for the word: \"jacket\"\n"," Answer:\n","\n","Why did the jacket go to therapy? Because it was feeling a little \"buttoned\" up!\n","\n","Total time: 9.7 sec.\n","\n","\n","Input tokens: 133, Output tokens: 21\n","\n","\n","------------------------- Word 11 -------------------------\n","Question: Now, tell me one short joke for the word: \"kangaroo\"\n"," Answer:\n","\n","Why did the kangaroo quit his job? Because he was hopping mad about the working conditions!\n","\n","Total time: 9.32 sec.\n","\n","\n","Input tokens: 134, Output tokens: 20\n","\n","\n","------------------------- Word 12 -------------------------\n","Question: Now, tell me one short joke for the word: \"lamp\"\n"," Answer:\n","\n","Why did the lamp go to therapy? Because it was feeling a little dim!\n","\n","Total time: 7.96 sec.\n","\n","\n","Input tokens: 132, Output tokens: 17\n","\n","\n","------------------------- Word 13 -------------------------\n","Question: Now, tell me one short joke for the word: \"mountain\"\n"," Answer:\n","\n","Why did the mountain go to the party? Because it was a peak performer!\n","\n","Total time: 7.85 sec.\n","\n","\n","Input tokens: 133, Output tokens: 17\n","\n","\n","------------------------- Word 14 -------------------------\n","Question: Now, tell me one short joke for the word: \"notebook\"\n"," Answer:\n","\n","Why did the notebook go to therapy? It had a lot of pages to turn!\n","\n","Total time: 8.25 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 15 -------------------------\n","Question: Now, tell me one short joke for the word: \"ocean\"\n"," Answer:\n","\n","Why did the ocean go to therapy? Because it was feeling a little \"drained\"!\n","\n","Total time: 9.41 sec.\n","\n","\n","Input tokens: 133, Output tokens: 20\n","\n","\n","------------------------- Word 16 -------------------------\n","Question: Now, tell me one short joke for the word: \"pencil\"\n"," Answer:\n","\n","Why did the pencil break up with its girlfriend? It was a sharp move!\n","\n","Total time: 8.02 sec.\n","\n","\n","Input tokens: 133, Output tokens: 17\n","\n","\n","------------------------- Word 17 -------------------------\n","Question: Now, tell me one short joke for the word: \"queen\"\n"," Answer:\n","\n","Why did the queen bring a ladder to the party? Because she wanted to take things to a higher level!\n","\n","Total time: 10.61 sec.\n","\n","\n","Input tokens: 132, Output tokens: 23\n","\n","\n","------------------------- Word 18 -------------------------\n","Question: Now, tell me one short joke for the word: \"river\"\n"," Answer:\n","\n","Why did the river go to therapy? Because it was feeling drained!\n","\n","Total time: 7.11 sec.\n","\n","\n","Input tokens: 132, Output tokens: 15\n","\n","\n","------------------------- Word 19 -------------------------\n","Question: Now, tell me one short joke for the word: \"star\"\n"," Answer:\n","\n","Why did the star go to therapy? Because it was feeling a little dim!\n","\n","Total time: 8.01 sec.\n","\n","\n","Input tokens: 132, Output tokens: 17\n","\n","\n","------------------------- Word 20 -------------------------\n","Question: Now, tell me one short joke for the word: \"tree\"\n"," Answer:\n","\n","Why did the tree go to the party? Because it wanted to branch out!\n","\n","Total time: 8.0 sec.\n","\n","\n","Input tokens: 132, Output tokens: 17\n","\n","\n","------------------------- Word 21 -------------------------\n","Question: Now, tell me one short joke for the word: \"umbrella\"\n"," Answer:\n","\n","Why did the umbrella go to therapy? Because it was feeling a little \"drained\"!\n","\n","Total time: 9.38 sec.\n","\n","\n","Input tokens: 133, Output tokens: 20\n","\n","\n","------------------------- Word 22 -------------------------\n","Question: Now, tell me one short joke for the word: \"village\"\n"," Answer:\n","\n","Why did the village goer bring a ladder to the party? Because he heard the drinks were on the house!\n","\n","Total time: 11.04 sec.\n","\n","\n","Input tokens: 133, Output tokens: 24\n","\n","\n","------------------------- Word 23 -------------------------\n","Question: Now, tell me one short joke for the word: \"window\"\n"," Answer:\n","\n","Why did the window go to therapy? It had a lot of \"pane\" issues!\n","\n","Total time: 8.7 sec.\n","\n","\n","Input tokens: 132, Output tokens: 19\n","\n","\n","------------------------- Word 24 -------------------------\n","Question: Now, tell me one short joke for the word: \"xylophone\"\n"," Answer:\n","\n","Why did the xylophone go to therapy? It had a lot of \"keys\" issues!\n","\n","Total time: 9.65 sec.\n","\n","\n","Input tokens: 134, Output tokens: 21\n","\n","\n","------------------------- Word 25 -------------------------\n","Question: Now, tell me one short joke for the word: \"yacht\"\n"," Answer:\n","\n","Why did the yachts go to therapy? Because they had anchor issues!\n","\n","Total time: 7.48 sec.\n","\n","\n","Input tokens: 133, Output tokens: 16\n","\n","\n","------------------------- Word 26 -------------------------\n","Question: Now, tell me one short joke for the word: \"zebra\"\n"," Answer:\n","\n","Why did the zebra go to the party? Because it was a stripe above the rest!\n","\n","Total time: 9.43 sec.\n","\n","\n","Input tokens: 133, Output tokens: 20\n","\n","\n","------------------------- Word 27 -------------------------\n","Question: Now, tell me one short joke for the word: \"balloon\"\n"," Answer:\n","\n","Why did the balloon go to the party? Because it was a blowout!\n","\n","Total time: 7.98 sec.\n","\n","\n","Input tokens: 133, Output tokens: 17\n","\n","\n","------------------------- Word 28 -------------------------\n","Question: Now, tell me one short joke for the word: \"camera\"\n"," Answer:\n","\n","Why did the camera go to therapy? It had a lot of focus issues!\n","\n","Total time: 7.87 sec.\n","\n","\n","Input tokens: 132, Output tokens: 17\n","\n","\n","------------------------- Word 29 -------------------------\n","Question: Now, tell me one short joke for the word: \"desert\"\n"," Answer:\n","\n","Why did the desert go to therapy? Because it was feeling dry!\n","\n","Total time: 7.02 sec.\n","\n","\n","Input tokens: 133, Output tokens: 15\n","\n","\n","------------------------- Word 30 -------------------------\n","Question: Now, tell me one short joke for the word: \"engine\"\n"," Answer:\n","\n","Why did the engine go to therapy? Because it was feeling a little \"car\"-sick!\n","\n","Total time: 9.67 sec.\n","\n","\n","Input tokens: 132, Output tokens: 21\n","\n","\n","------------------------- Word 31 -------------------------\n","Question: Now, tell me one short joke for the word: \"flower\"\n"," Answer:\n","\n","Why did the flower go to the party? Because it was a blooming good time!\n","\n","Total time: 8.94 sec.\n","\n","\n","Input tokens: 132, Output tokens: 19\n","\n","\n","------------------------- Word 32 -------------------------\n","Question: Now, tell me one short joke for the word: \"garden\"\n"," Answer:\n","\n","Why did the garden go to therapy? Because it was feeling a little wilted!\n","\n","Total time: 8.46 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 33 -------------------------\n","Question: Now, tell me one short joke for the word: \"honey\"\n"," Answer:\n","\n","Why did the honey go to the doctor? Because it was feeling a little sticky!\n","\n","Total time: 8.39 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 34 -------------------------\n","Question: Now, tell me one short joke for the word: \"iceberg\"\n"," Answer:\n","\n","Why did the iceberg go to therapy? Because it was feeling a little \"chilly\"!\n","\n","Total time: 9.35 sec.\n","\n","\n","Input tokens: 133, Output tokens: 20\n","\n","\n","------------------------- Word 35 -------------------------\n","Question: Now, tell me one short joke for the word: \"jungle\"\n"," Answer:\n","\n","Why did the jungle go to the party? Because it was a wild time!\n","\n","Total time: 8.05 sec.\n","\n","\n","Input tokens: 133, Output tokens: 17\n","\n","\n","------------------------- Word 36 -------------------------\n","Question: Now, tell me one short joke for the word: \"kite\"\n"," Answer:\n","\n","Why did the kite go to therapy? Because it had a lot of strings attached!\n","\n","Total time: 8.34 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 37 -------------------------\n","Question: Now, tell me one short joke for the word: \"ladder\"\n"," Answer:\n","\n","Why did the ladder go to therapy? Because it was feeling a little \"rung\" out!\n","\n","Total time: 9.3 sec.\n","\n","\n","Input tokens: 133, Output tokens: 20\n","\n","\n","------------------------- Word 38 -------------------------\n","Question: Now, tell me one short joke for the word: \"moon\"\n"," Answer:\n","\n","Why did the astronaut break up with the moon? Because it was a phase!\n","\n","Total time: 7.98 sec.\n","\n","\n","Input tokens: 132, Output tokens: 17\n","\n","\n","------------------------- Word 39 -------------------------\n","Question: Now, tell me one short joke for the word: \"nest\"\n"," Answer:\n","\n","Why did the bird go to therapy? It had a fowl temper and needed to work on its nest issues!\n","\n","Total time: 11.05 sec.\n","\n","\n","Input tokens: 132, Output tokens: 24\n","\n","\n","------------------------- Word 40 -------------------------\n","Question: Now, tell me one short joke for the word: \"octopus\"\n"," Answer:\n","\n","Why did the octopus go to the party? Because it was an ink-redible dancer!\n","\n","Total time: 9.37 sec.\n","\n","\n","Input tokens: 133, Output tokens: 20\n","\n","\n","------------------------- Word 41 -------------------------\n","Question: Now, tell me one short joke for the word: \"pirate\"\n"," Answer:\n","\n","Why did the pirate quit his job? Because he was sick of all the arrrr-guments!\n","\n","Total time: 9.83 sec.\n","\n","\n","Input tokens: 133, Output tokens: 21\n","\n","\n","------------------------- Word 42 -------------------------\n","Question: Now, tell me one short joke for the word: \"quilt\"\n"," Answer:\n","\n","Why did the quilt go to therapy? Because it was feeling a little \"stitched\"!\n","\n","Total time: 9.34 sec.\n","\n","\n","Input tokens: 133, Output tokens: 20\n","\n","\n","------------------------- Word 43 -------------------------\n","Question: Now, tell me one short joke for the word: \"robot\"\n"," Answer:\n","\n","Why did the robot go on a diet? Because it wanted to lose some bytes!\n","\n","Total time: 8.52 sec.\n","\n","\n","Input tokens: 132, Output tokens: 18\n","\n","\n","------------------------- Word 44 -------------------------\n","Question: Now, tell me one short joke for the word: \"swan\"\n"," Answer:\n","\n","Why did the swan go to the doctor? It had a fowl cough!\n","\n","Total time: 8.22 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 45 -------------------------\n","Question: Now, tell me one short joke for the word: \"telescope\"\n"," Answer:\n","\n","Why did the telescope go to therapy? It was feeling a little \"out of focus\"!\n","\n","Total time: 9.12 sec.\n","\n","\n","Input tokens: 133, Output tokens: 20\n","\n","\n","------------------------- Word 46 -------------------------\n","Question: Now, tell me one short joke for the word: \"unicorn\"\n"," Answer:\n","\n","Why did the unicorn get kicked out of the movie theater? Because it was using its horn to pop the corn!\n","\n","Total time: 11.33 sec.\n","\n","\n","Input tokens: 132, Output tokens: 24\n","\n","\n","------------------------- Word 47 -------------------------\n","Question: Now, tell me one short joke for the word: \"violin\"\n"," Answer:\n","\n","Why was the violinist's computer slow? It had a lot of strings attached!\n","\n","Total time: 8.29 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 48 -------------------------\n","Question: Now, tell me one short joke for the word: \"whale\"\n"," Answer:\n","\n","Why did the whale go to the ocean party? Because he heard it was a whale of a time!\n","\n","Total time: 10.18 sec.\n","\n","\n","Input tokens: 133, Output tokens: 22\n","\n","\n","------------------------- Word 49 -------------------------\n","Question: Now, tell me one short joke for the word: \"x-ray\"\n"," Answer:\n","\n","Why did the X-ray go to therapy? It had a lot of internal issues!\n","\n","Total time: 8.43 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 50 -------------------------\n","Question: Now, tell me one short joke for the word: \"laptop\"\n"," Answer:\n","\n","Why did the laptop go to therapy? It had a lot of bytes to unpack!\n","\n","Total time: 8.31 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","\n","\n","========================= Run 2 =========================\n","\n","\n","------------------------- Word 1 -------------------------\n","Question: Now, tell me one short joke for the word: \"apple\"\n"," Answer:\n","\n","Why did the apple join the gym? To get some core strength!\n","\n","Total time: 7.05 sec.\n","\n","\n","Input tokens: 132, Output tokens: 15\n","\n","\n","------------------------- Word 2 -------------------------\n","Question: Now, tell me one short joke for the word: \"book\"\n"," Answer:\n","\n","Why did the book go to therapy? Because it had a bad chapter in its life!\n","\n","Total time: 8.94 sec.\n","\n","\n","Input tokens: 132, Output tokens: 19\n","\n","\n","------------------------- Word 3 -------------------------\n","Question: Now, tell me one short joke for the word: \"car\"\n"," Answer:\n","\n","Why did the car go to the doctor? It was feeling a little \"car\"-sick!\n","\n","Total time: 9.72 sec.\n","\n","\n","Input tokens: 132, Output tokens: 21\n","\n","\n","------------------------- Word 4 -------------------------\n","Question: Now, tell me one short joke for the word: \"dog\"\n"," Answer:\n","\n","Why did the dog go to the vet? Because he was feeling ruff!\n","\n","Total time: 7.97 sec.\n","\n","\n","Input tokens: 132, Output tokens: 17\n","\n","\n","------------------------- Word 5 -------------------------\n","Question: Now, tell me one short joke for the word: \"elephant\"\n"," Answer:\n","\n","Why did the elephant quit the circus? Because it was tired of working for peanuts!\n","\n","Total time: 8.44 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 6 -------------------------\n","Question: Now, tell me one short joke for the word: \"forest\"\n"," Answer:\n","\n","Why did the tree go to the party in the forest? Because it wanted to branch out!\n","\n","Total time: 9.36 sec.\n","\n","\n","Input tokens: 132, Output tokens: 20\n","\n","\n","------------------------- Word 7 -------------------------\n","Question: Now, tell me one short joke for the word: \"guitar\"\n"," Answer:\n","\n","Why was the guitar sad? Because it was out of tune!\n","\n","Total time: 6.66 sec.\n","\n","\n","Input tokens: 133, Output tokens: 14\n","\n","\n","------------------------- Word 8 -------------------------\n","Question: Now, tell me one short joke for the word: \"house\"\n"," Answer:\n","\n","Why did the house go to therapy? Because it had a few walls to work through!\n","\n","Total time: 8.86 sec.\n","\n","\n","Input tokens: 132, Output tokens: 19\n","\n","\n","------------------------- Word 9 -------------------------\n","Question: Now, tell me one short joke for the word: \"island\"\n"," Answer:\n","\n","Why did the island go to therapy? Because it was feeling a little isolated!\n","\n","Total time: 7.93 sec.\n","\n","\n","Input tokens: 133, Output tokens: 17\n","\n","\n","------------------------- Word 10 -------------------------\n","Question: Now, tell me one short joke for the word: \"jacket\"\n"," Answer:\n","\n","Why did the jacket go to therapy? Because it was feeling a little \"buttoned\" up!\n","\n","Total time: 9.73 sec.\n","\n","\n","Input tokens: 133, Output tokens: 21\n","\n","\n","------------------------- Word 11 -------------------------\n","Question: Now, tell me one short joke for the word: \"kangaroo\"\n"," Answer:\n","\n","Why did the kangaroo quit his job? Because he was hopping mad about the working conditions!\n","\n","Total time: 9.38 sec.\n","\n","\n","Input tokens: 134, Output tokens: 20\n","\n","\n","------------------------- Word 12 -------------------------\n","Question: Now, tell me one short joke for the word: \"lamp\"\n"," Answer:\n","\n","Why did the lamp go to therapy? Because it was feeling a little dim!\n","\n","Total time: 8.01 sec.\n","\n","\n","Input tokens: 132, Output tokens: 17\n","\n","\n","------------------------- Word 13 -------------------------\n","Question: Now, tell me one short joke for the word: \"mountain\"\n"," Answer:\n","\n","Why did the mountain go to the party? Because it was a peak performer!\n","\n","Total time: 7.89 sec.\n","\n","\n","Input tokens: 133, Output tokens: 17\n","\n","\n","------------------------- Word 14 -------------------------\n","Question: Now, tell me one short joke for the word: \"notebook\"\n"," Answer:\n","\n","Why did the notebook go to therapy? It had a lot of pages to turn!\n","\n","Total time: 8.3 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 15 -------------------------\n","Question: Now, tell me one short joke for the word: \"ocean\"\n"," Answer:\n","\n","Why did the ocean go to therapy? Because it was feeling a little \"drained\"!\n","\n","Total time: 9.35 sec.\n","\n","\n","Input tokens: 133, Output tokens: 20\n","\n","\n","------------------------- Word 16 -------------------------\n","Question: Now, tell me one short joke for the word: \"pencil\"\n"," Answer:\n","\n","Why did the pencil break up with its girlfriend? It was a sharp move!\n","\n","Total time: 7.96 sec.\n","\n","\n","Input tokens: 133, Output tokens: 17\n","\n","\n","------------------------- Word 17 -------------------------\n","Question: Now, tell me one short joke for the word: \"queen\"\n"," Answer:\n","\n","Why did the queen bring a ladder to the party? Because she wanted to take things to a higher level!\n","\n","Total time: 10.6 sec.\n","\n","\n","Input tokens: 132, Output tokens: 23\n","\n","\n","------------------------- Word 18 -------------------------\n","Question: Now, tell me one short joke for the word: \"river\"\n"," Answer:\n","\n","Why did the river go to therapy? Because it was feeling drained!\n","\n","Total time: 7.06 sec.\n","\n","\n","Input tokens: 132, Output tokens: 15\n","\n","\n","------------------------- Word 19 -------------------------\n","Question: Now, tell me one short joke for the word: \"star\"\n"," Answer:\n","\n","Why did the star go to therapy? Because it was feeling a little dim!\n","\n","Total time: 7.96 sec.\n","\n","\n","Input tokens: 132, Output tokens: 17\n","\n","\n","------------------------- Word 20 -------------------------\n","Question: Now, tell me one short joke for the word: \"tree\"\n"," Answer:\n","\n","Why did the tree go to the party? Because it wanted to branch out!\n","\n","Total time: 8.01 sec.\n","\n","\n","Input tokens: 132, Output tokens: 17\n","\n","\n","------------------------- Word 21 -------------------------\n","Question: Now, tell me one short joke for the word: \"umbrella\"\n"," Answer:\n","\n","Why did the umbrella go to therapy? Because it was feeling a little \"drained\"!\n","\n","Total time: 9.39 sec.\n","\n","\n","Input tokens: 133, Output tokens: 20\n","\n","\n","------------------------- Word 22 -------------------------\n","Question: Now, tell me one short joke for the word: \"village\"\n"," Answer:\n","\n","Why did the village goer bring a ladder to the party? Because he heard the drinks were on the house!\n","\n","Total time: 11.01 sec.\n","\n","\n","Input tokens: 133, Output tokens: 24\n","\n","\n","------------------------- Word 23 -------------------------\n","Question: Now, tell me one short joke for the word: \"window\"\n"," Answer:\n","\n","Why did the window go to therapy? It had a lot of \"pane\" issues!\n","\n","Total time: 8.71 sec.\n","\n","\n","Input tokens: 132, Output tokens: 19\n","\n","\n","------------------------- Word 24 -------------------------\n","Question: Now, tell me one short joke for the word: \"xylophone\"\n"," Answer:\n","\n","Why did the xylophone go to therapy? It had a lot of \"keys\" issues!\n","\n","Total time: 9.64 sec.\n","\n","\n","Input tokens: 134, Output tokens: 21\n","\n","\n","------------------------- Word 25 -------------------------\n","Question: Now, tell me one short joke for the word: \"yacht\"\n"," Answer:\n","\n","Why did the yachts go to therapy? Because they had anchor issues!\n","\n","Total time: 7.5 sec.\n","\n","\n","Input tokens: 133, Output tokens: 16\n","\n","\n","------------------------- Word 26 -------------------------\n","Question: Now, tell me one short joke for the word: \"zebra\"\n"," Answer:\n","\n","Why did the zebra go to the party? Because it was a stripe above the rest!\n","\n","Total time: 9.49 sec.\n","\n","\n","Input tokens: 133, Output tokens: 20\n","\n","\n","------------------------- Word 27 -------------------------\n","Question: Now, tell me one short joke for the word: \"balloon\"\n"," Answer:\n","\n","Why did the balloon go to the party? Because it was a blowout!\n","\n","Total time: 7.98 sec.\n","\n","\n","Input tokens: 133, Output tokens: 17\n","\n","\n","------------------------- Word 28 -------------------------\n","Question: Now, tell me one short joke for the word: \"camera\"\n"," Answer:\n","\n","Why did the camera go to therapy? It had a lot of focus issues!\n","\n","Total time: 7.85 sec.\n","\n","\n","Input tokens: 132, Output tokens: 17\n","\n","\n","------------------------- Word 29 -------------------------\n","Question: Now, tell me one short joke for the word: \"desert\"\n"," Answer:\n","\n","Why did the desert go to therapy? Because it was feeling dry!\n","\n","Total time: 7.0 sec.\n","\n","\n","Input tokens: 133, Output tokens: 15\n","\n","\n","------------------------- Word 30 -------------------------\n","Question: Now, tell me one short joke for the word: \"engine\"\n"," Answer:\n","\n","Why did the engine go to therapy? Because it was feeling a little \"car\"-sick!\n","\n","Total time: 9.67 sec.\n","\n","\n","Input tokens: 132, Output tokens: 21\n","\n","\n","------------------------- Word 31 -------------------------\n","Question: Now, tell me one short joke for the word: \"flower\"\n"," Answer:\n","\n","Why did the flower go to the party? Because it was a blooming good time!\n","\n","Total time: 8.94 sec.\n","\n","\n","Input tokens: 132, Output tokens: 19\n","\n","\n","------------------------- Word 32 -------------------------\n","Question: Now, tell me one short joke for the word: \"garden\"\n"," Answer:\n","\n","Why did the garden go to therapy? Because it was feeling a little prickly!\n","\n","Total time: 8.48 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 33 -------------------------\n","Question: Now, tell me one short joke for the word: \"honey\"\n"," Answer:\n","\n","Why did the honey go to the doctor? Because it was feeling a little sticky!\n","\n","Total time: 8.4 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 34 -------------------------\n","Question: Now, tell me one short joke for the word: \"iceberg\"\n"," Answer:\n","\n","Why did the iceberg go to therapy? Because it had a lot of \"deep-seated\" issues!\n","\n","Total time: 10.17 sec.\n","\n","\n","Input tokens: 133, Output tokens: 22\n","\n","\n","------------------------- Word 35 -------------------------\n","Question: Now, tell me one short joke for the word: \"jungle\"\n"," Answer:\n","\n","Why did the jungle go to the party? Because it was a wild time!\n","\n","Total time: 8.08 sec.\n","\n","\n","Input tokens: 133, Output tokens: 17\n","\n","\n","------------------------- Word 36 -------------------------\n","Question: Now, tell me one short joke for the word: \"kite\"\n"," Answer:\n","\n","Why did the kite go to the party? Because it was a high flyer!\n","\n","Total time: 7.94 sec.\n","\n","\n","Input tokens: 133, Output tokens: 17\n","\n","\n","------------------------- Word 37 -------------------------\n","Question: Now, tell me one short joke for the word: \"ladder\"\n"," Answer:\n","\n","Why did the ladder go to therapy? Because it was feeling a little \"rung\" out!\n","\n","Total time: 9.32 sec.\n","\n","\n","Input tokens: 133, Output tokens: 20\n","\n","\n","------------------------- Word 38 -------------------------\n","Question: Now, tell me one short joke for the word: \"moon\"\n"," Answer:\n","\n","Why did the astronaut break up with the moon? Because it was a phase!\n","\n","Total time: 7.96 sec.\n","\n","\n","Input tokens: 132, Output tokens: 17\n","\n","\n","------------------------- Word 39 -------------------------\n","Question: Now, tell me one short joke for the word: \"nest\"\n"," Answer:\n","\n","Why did the bird go to therapy? It had a fowl temper and needed to work on its nest issues!\n","\n","Total time: 11.02 sec.\n","\n","\n","Input tokens: 132, Output tokens: 24\n","\n","\n","------------------------- Word 40 -------------------------\n","Question: Now, tell me one short joke for the word: \"octopus\"\n"," Answer:\n","\n","Why did the octopus go to the party? Because it was an ink-redible dancer!\n","\n","Total time: 9.43 sec.\n","\n","\n","Input tokens: 133, Output tokens: 20\n","\n","\n","------------------------- Word 41 -------------------------\n","Question: Now, tell me one short joke for the word: \"pirate\"\n"," Answer:\n","\n","Why did the pirate quit his job? Because he was sick of all the arrrr-guments!\n","\n","Total time: 9.9 sec.\n","\n","\n","Input tokens: 133, Output tokens: 21\n","\n","\n","------------------------- Word 42 -------------------------\n","Question: Now, tell me one short joke for the word: \"quilt\"\n"," Answer:\n","\n","Why did the quilt go to therapy? Because it was feeling a little frayed!\n","\n","Total time: 8.33 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 43 -------------------------\n","Question: Now, tell me one short joke for the word: \"robot\"\n"," Answer:\n","\n","Why did the robot go on a diet? Because it wanted to lose some bytes!\n","\n","Total time: 8.45 sec.\n","\n","\n","Input tokens: 132, Output tokens: 18\n","\n","\n","------------------------- Word 44 -------------------------\n","Question: Now, tell me one short joke for the word: \"swan\"\n"," Answer:\n","\n","Why did the swan go to therapy? Because it had a fowl temper!\n","\n","Total time: 8.37 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 45 -------------------------\n","Question: Now, tell me one short joke for the word: \"telescope\"\n"," Answer:\n","\n","Why did the telescope go to therapy? It had a lot of \"space\" issues!\n","\n","Total time: 8.72 sec.\n","\n","\n","Input tokens: 133, Output tokens: 19\n","\n","\n","------------------------- Word 46 -------------------------\n","Question: Now, tell me one short joke for the word: \"unicorn\"\n"," Answer:\n","\n","Why did the unicorn get kicked out of the movie theater? Because it was using its horn to pop the corn!\n","\n","Total time: 11.3 sec.\n","\n","\n","Input tokens: 132, Output tokens: 24\n","\n","\n","------------------------- Word 47 -------------------------\n","Question: Now, tell me one short joke for the word: \"violin\"\n"," Answer:\n","\n","Why was the violinist's computer slow? It had a lot of strings attached!\n","\n","Total time: 8.26 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 48 -------------------------\n","Question: Now, tell me one short joke for the word: \"whale\"\n"," Answer:\n","\n","Why did the whale go to the ocean party? Because he heard it was a whale of a time!\n","\n","Total time: 10.19 sec.\n","\n","\n","Input tokens: 133, Output tokens: 22\n","\n","\n","------------------------- Word 49 -------------------------\n","Question: Now, tell me one short joke for the word: \"x-ray\"\n"," Answer:\n","\n","Why did the x-ray go to therapy? Because it was feeling a little exposed!\n","\n","Total time: 8.47 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","------------------------- Word 50 -------------------------\n","Question: Now, tell me one short joke for the word: \"laptop\"\n"," Answer:\n","\n","Why did the laptop go to therapy? It had a lot of bytes to unpack!\n","\n","Total time: 8.34 sec.\n","\n","\n","Input tokens: 133, Output tokens: 18\n","\n","\n","\n","\n","========================= RESULTS =========================\n","\n","\n","      Finished 2 Runs with 50 Words/Run.\n","\n","\n","      Total Prompts: 100\n","\n","      Total Input Tokens: 13266, AVG/Prompt: 132.66\n","\n","      Total Output Tokens: 1879, AVG/Prompt: 18.79\n","\n","      --------------------------------------------------\n","\n","      Total Inference Emissions: 0.053kg CO₂eq\n","\n","\n","      Emissions / 1.000.000 Input Tokens: 4.016kg CO₂eq\n","\n","      Emissions / 1.000.000 Output Tokens: 28.350kg CO₂eq\n","\n","      Emissions / 1.000 Prompts: 0.533kg CO₂eq\n","\n","\n","      \n"]}],"source":["avg_time = 20\n","avg_in_tok = 103\n","avg_out_tok = 30\n","\n","#avg_time = 4.5\n","#avg_in_tok = 103\n","#avg_out_tok = 25\n","\n","# Number of runs\n","n = 2 # Change to 5 for all the other tests\n","num_words = len(words)\n","total_prompts = n*num_words\n","\n","total_input_tokens = 0\n","total_output_tokens = 0\n","\n","print(\"=\"*20 + f\" INFERENCE TEST \" + \"=\"*20 + \n","      \"\\n\\n\" + \n","      f\"\"\"\n","      Starting Test with {n} Runs and {num_words} Words/Run. \\n\n","      Total Prompts: {total_prompts}\\n\\n\n","      Expected Runtime: {(total_prompts*avg_time)/60}min \\n\n","      Expected Input Tokens: {avg_in_tok*total_prompts} \\n\n","      Expected Output Tokens: {avg_out_tok*total_prompts} \\n\\n\n","      \"\"\")\n","\n","tracker = EmissionsTracker(project_name=model_name, log_level=\"error\", pue = 1.22)\n","tracker.start()\n","\n","# Run the function for each word in the array\n","for i in range(n):\n","    print(\"=\"*25 + f\" Run {i+1} \" + \"=\"*25)\n","    print(\"\\n\")\n","    for idx, word in enumerate(words):\n","        print(\"-\"*25 + f\" Word {idx+1} \" + \"-\"*25)\n","        #prompt = create_prompt(word)\n","        output, input_token_count, output_token_count = query_model(word, temperature=0.2)\n","        \n","        total_input_tokens += input_token_count\n","        total_output_tokens += output_token_count\n","        \n","        print(output)\n","        print(\"\\n\")\n","        print(f\"Input tokens: {input_token_count}, Output tokens: {output_token_count}\")\n","        print(\"\\n\")\n","    print(\"\\n\")\n","    \n","emissions: float = tracker.stop()\n","\n","em_i = emissions/total_input_tokens\n","em_o = emissions/total_output_tokens\n","em_p = emissions/total_prompts\n","\n","print(\"=\"*25 + f\" RESULTS \" + \"=\"*25 + \n","      \"\\n\\n\" + \n","      f\"\"\"\n","      Finished {n} Runs with {num_words} Words/Run.\\n\\n\n","      Total Prompts: {total_prompts}\\n\n","      Total Input Tokens: {total_input_tokens}, AVG/Prompt: {total_input_tokens/total_prompts}\\n\n","      Total Output Tokens: {total_output_tokens}, AVG/Prompt: {total_output_tokens/total_prompts}\\n\n","      \"\"\" + \n","      \n","      \"-\"*50 + \"\\n\" +\n","      \n","      f\"\"\"\n","      Total Inference Emissions: {emissions:.3f}kg CO₂eq\\n\\n\n","      Emissions / 1.000.000 Input Tokens: {em_i * 1000000:.3f}kg CO₂eq\\n\n","      Emissions / 1.000.000 Output Tokens: {em_o * 1000000:.3f}kg CO₂eq\\n\n","      Emissions / 1.000 Prompts: {em_p * 1000:.3f}kg CO₂eq\\n\n","\n","      \"\"\"\n","     )"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Results saved to meta-llama/Meta-Llama-3-70B-Instruct-emissiondata.csv\n"]}],"source":["results = [\n","    [\"Runs\", n],\n","    [\"Words per Run\", num_words],\n","    [\"Total Prompts\", total_prompts],\n","    [\"Total Input Tokens\", total_input_tokens],\n","    [\"Avg Input Tokens per Prompt\", round(total_input_tokens / total_prompts, 3)],\n","    [\"Total Output Tokens\", total_output_tokens],\n","    [\"Avg Output Tokens per Prompt\", round(total_output_tokens / total_prompts, 3)],\n","    [\"Total Emissions (kg CO₂eq)\", round(emissions, 3)],\n","    [\"Emissions per Million Input Tokens (kg CO₂eq)\", round(em_i * 1000000, 3)],\n","    [\"Emissions per Million Output Tokens (kg CO₂eq)\", round(em_o * 1000000, 3)],\n","    [\"Emissions per Thousand Prompts (kg CO₂eq)\", round(em_p * 1000, 3)]\n","]\n","\n","# Ensure the directory exists\n","output_file_path = f'{model_name}-emissiondata.csv'\n","os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n","\n","with open(output_file_path, 'w', newline='') as f:\n","    writer = csv.writer(f)\n","    writer.writerow([\"Metric\", \"Value\"])\n","    writer.writerows(results)\n","\n","print(f\"Results saved to {output_file_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Approach without Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T14:41:26.753409Z","iopub.status.busy":"2024-05-28T14:41:26.753054Z","iopub.status.idle":"2024-05-28T14:41:26.759565Z","shell.execute_reply":"2024-05-28T14:41:26.758472Z","shell.execute_reply.started":"2024-05-28T14:41:26.753381Z"},"trusted":true},"outputs":[],"source":["# Write a Text Generation Function\n","#@track_emissions(project_name=model_name)\n","#def generate_text(prompt, max_length=50):\n","#    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","#    with torch.no_grad():\n","#        outputs = model.generate(\n","#            **inputs, \n","#            #max_length=max_length,\n","#            pad_token_id=tokenizer.eos_token_id,\n","#            max_new_tokens=max_length\n","#        )\n","#    return tokenizer.decode(outputs[0], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-28T14:41:27.003272Z","iopub.status.busy":"2024-05-28T14:41:27.002587Z","iopub.status.idle":"2024-05-28T14:41:27.007995Z","shell.execute_reply":"2024-05-28T14:41:27.007015Z","shell.execute_reply.started":"2024-05-28T14:41:27.003238Z"},"trusted":true},"outputs":[],"source":["#def create_prompt(word): \n","#    prompt = f\"\"\"\n","#    You are an AI-Assistant that tells jokes for a given word.\n","#    Generate a short joke that is exactly 2 sentences long.\n","#    Do not include any follow-up questions or explanations.#\n","#\n","#    For example, a joke for the word \"yogurt\":\n","#    'Why did the yogurt go to the art gallery? Because it wanted to be cultured!'#\n","#\n","#    Now, tell me one short joke for the word \"{word}\".\n","#    \"\"\"\n","#    return prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-28T14:41:33.337248Z","iopub.status.busy":"2024-05-28T14:41:33.336126Z","iopub.status.idle":"2024-05-28T14:50:51.430457Z","shell.execute_reply":"2024-05-28T14:50:51.429479Z","shell.execute_reply.started":"2024-05-28T14:41:33.337202Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["#tracker = EmissionsTracker(project_name=model_name, log_level=\"error\", pue = 1.22)#, output_file=f'{model_name}_emissions.csv')\n","#tracker.start()\n","\n","# Number of runs\n","#n = 1\n","\n","# Run the function for each word in the array\n","#for i in range(n):\n","#    print(\"=\"*25 + f\" Run {i+1} \" + \"=\"*25)\n","#    print(\"\\n\")\n","#    for idx, word in enumerate(words):\n","#        print(\"-\"*25 + f\" Word {idx+1} \" + \"-\"*25)\n","#        prompt = create_prompt(word)\n","#        output = generate_text(prompt)\n","#        print(output)\n","#        print(\"\\n\")\n","#    print(\"\\n\")\n","    \n","#emissions: float = tracker.stop()\n","#print(emissions)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4880117,"sourceId":8230136,"sourceType":"datasetVersion"},{"modelInstanceId":28079,"sourceId":33547,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelInstanceId":28083,"sourceId":33551,"sourceType":"modelInstanceVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
