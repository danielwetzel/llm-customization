engine,model_type,parameters,num_prompts,total_time,time_per_prompt,tok_per_sec,total_out_tok,total_in_tok,avg_out_tok,avg_in_tok,actual_emissions_per_10k_prompts,actual_total_energy_per_10k_prompts,actual_cpu_energy_per_10k_prompts,actual_gpu_energy_per_10k_prompts,actual_ram_energy_per_10k_prompts,actual_idle_gpu_energy_per_10k_prompts,actual_non_idle_gpu_energy_per_10k_prompts
vllm,Llama-3-8B,8,7500,529.6417527198792,0.07061890036265055,1013.5284789073464,536807.0,1399950.0,71.57426666666667,186.66,0.0545325342858232,0.08201019039623854,0.010171567457649333,0.055541521336885204,0.016297101601704,0.021970324557269064,0.03357119677961613
transformers,Llama-3-8B,8,7500,2973.026404619217,0.3964035206158956,149.54223053963867,444593.0,1399950.0,59.279066666666665,186.66,0.25840223494565173,0.38860501834802186,0.05709341347380466,0.24003319664862588,0.09147840822559093,0.1233255397471675,0.11670765690145836
