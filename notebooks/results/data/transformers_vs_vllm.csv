engine,model_type,parameters,num_prompts,total_time,time_per_prompt,tok_per_sec,total_out_tok,total_in_tok,avg_out_tok,avg_in_tok,actual_emissions_per_10k_prompts,actual_total_energy_per_10k_prompts,actual_cpu_energy_per_10k_prompts,actual_gpu_energy_per_10k_prompts,actual_ram_energy_per_10k_prompts,actual_idle_gpu_energy_per_10k_prompts,actual_non_idle_gpu_energy_per_10k_prompts
vllm,Llama-3-8B,8,7500,529.6417527198792,0.07061890036265055,1013.5284789073464,536807.0,1399950.0,71.57426666666667,186.66,0.0545325342858232,0.08201019039623854,0.010171567457649333,0.055541521336885204,0.016297101601704,0.021970324557269064,0.03357119677961613
transformers,Llama-3-8B,8,7500,1505.43225979805,0.20072430130640664,179.99813557625677,270975.0,1399950.0,36.13,186.66,0.1285524103687136,0.1933269338809061,0.028910241138705467,0.11809219589590333,0.046324496846297324,0.062447560406437626,0.055644635489465695
