engine,model_type,parameters,num_prompts,total_time,time_per_prompt,tok_per_sec,total_out_tok,total_in_tok,avg_out_tok,avg_in_tok,actual_emissions_per_10k_prompts,actual_total_energy_per_10k_prompts,actual_cpu_energy_per_10k_prompts,actual_gpu_energy_per_10k_prompts,actual_ram_energy_per_10k_prompts,actual_idle_gpu_energy_per_10k_prompts,actual_non_idle_gpu_energy_per_10k_prompts
vllm,Llama-3-8B,8,7500,643.117311000824,0.08574897480010986,1009.8219856488485,649434.0,1549950.0,86.5912,206.66,0.0640536371206576,0.09632875208593292,0.012350677922853602,0.06419055197462267,0.019787522188456533,0.026677458826700848,0.03751309314792182
transformers,Llama-3-8B,8,7500,2978.908830165863,0.39718784402211504,219.68111053723084,654410.0,1549950.0,87.25466666666667,206.66,0.2572723133244789,0.3869057559077415,0.0572063872032916,0.2380390264310685,0.09166034227338093,0.12356955147354692,0.11446947495752159
