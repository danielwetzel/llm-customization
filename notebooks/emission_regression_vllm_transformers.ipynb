{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the individual CSV files\n",
    "csv_files_output = {\n",
    "    'vllm': 'emission_data/vllm_meta-llama/Meta-Llama-3-8B-Instruct_emission_data.csv',\n",
    "    'transformers': 'emission_data/transformers_meta-llama/Meta-Llama-3-8B-Instruct_emission_data.csv',\n",
    "}\n",
    "\n",
    "# Read the emissions data\n",
    "emissions_data = pd.read_csv('emissions_vllm_transformers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store metadata\n",
    "total_time = []\n",
    "time_per_prompt = []\n",
    "tok_per_sec = []\n",
    "engine = []\n",
    "parameters = []\n",
    "num_prompts = []\n",
    "total_emissions = []\n",
    "cpu_energy = []\n",
    "gpu_energy = []\n",
    "ram_energy = []\n",
    "total_energy = []\n",
    "total_output_tokens = []\n",
    "total_input_tokens = []\n",
    "avg_input_tokens = []\n",
    "avg_output_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and extract metadata from each CSV file\n",
    "for model, file in csv_files_output.items():\n",
    "    data = pd.read_csv(file)\n",
    "    time = data.loc[data['Metric'] == 'Total Time', 'Value'].values[0]\n",
    "    time_p_prompt = data.loc[data['Metric'] == 'AVG. Time / Prompt', 'Value'].values[0] / 1000 #Time is in ms\n",
    "    tok_p_sec = data.loc[data['Metric'] == 'AVG. Tokens / Second', 'Value'].values[0]\n",
    "    prompts = data.loc[data['Metric'] == 'Total Prompts', 'Value'].values[0]\n",
    "    output_tokens = data.loc[data['Metric'] == 'Total Output Tokens', 'Value'].values[0]\n",
    "    input_tokens = data.loc[data['Metric'] == 'Total Input Tokens', 'Value'].values[0]\n",
    "    avg_i_tok = data.loc[data['Metric'] == 'AVG. Input Tokens / Prompt', 'Value'].values[0]\n",
    "    avg_o_tok = data.loc[data['Metric'] == 'AVG. Output Tokens / Prompt', 'Value'].values[0]\n",
    "    total_time.append(float(time))\n",
    "    time_per_prompt.append(float(time_p_prompt))\n",
    "    tok_per_sec.append(float(tok_p_sec))\n",
    "    parameters.append(8)\n",
    "    num_prompts.append(int(prompts))\n",
    "    engine.append(model)\n",
    "    total_output_tokens.append(float(output_tokens))\n",
    "    total_input_tokens.append(float(input_tokens))\n",
    "    avg_input_tokens.append(float(avg_i_tok))\n",
    "    avg_output_tokens.append(float(avg_o_tok))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract emissions data\n",
    "for idx, model in enumerate(csv_files_output.keys()):\n",
    "    model_emissions = emissions_data\n",
    "    total_emissions.append(model_emissions['emissions'].values[idx])\n",
    "    cpu_energy.append(model_emissions['cpu_energy'].values[idx])\n",
    "    gpu_energy.append(model_emissions['gpu_energy'].values[idx])\n",
    "    ram_energy.append(model_emissions['ram_energy'].values[idx])\n",
    "    total_energy.append(model_emissions['energy_consumed'].values[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0408994007143674, 0.0964143077765352]\n",
      "[0.007628675593237, 0.0216826808540291]\n",
      "[0.0416561410026639, 0.0885691469219275]\n",
      "[0.012222826201278, 0.034743372634723]\n",
      "[0.0615076427971789, 0.1449952004106796]\n"
     ]
    }
   ],
   "source": [
    "print(total_emissions)\n",
    "print(cpu_energy)\n",
    "print(gpu_energy)\n",
    "print(ram_energy)\n",
    "print(total_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for regression and visualization\n",
    "total_time = np.array(total_time)\n",
    "time_per_prompt = np.array(time_per_prompt)\n",
    "tok_per_sec = np.array(tok_per_sec)\n",
    "parameters = np.array(parameters)\n",
    "num_prompts = np.array(num_prompts)\n",
    "total_output_tokens = np.array(total_output_tokens)\n",
    "total_input_tokens = np.array(total_input_tokens)\n",
    "avg_input_tokens = np.array(avg_input_tokens)\n",
    "avg_output_tokens = np.array(avg_output_tokens)\n",
    "total_emissions = np.array(total_emissions)\n",
    "cpu_energy = np.array(cpu_energy)\n",
    "gpu_energy = np.array(gpu_energy)\n",
    "ram_energy = np.array(ram_energy)\n",
    "total_energy = np.array(total_energy)\n",
    "engine = np.array(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 529.64175272 1505.4322598 ]\n"
     ]
    }
   ],
   "source": [
    "print(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01647774 0.04683567]\n",
      "[0.02197032 0.06244756]\n",
      "[0.04165614 0.08856915]\n",
      "[0.0335712  0.05564464]\n"
     ]
    }
   ],
   "source": [
    "idle_gpu_power = 28*4 # 28W per GPU, 4 GPUs\n",
    "\n",
    "total_idle_gpu_energy = (idle_gpu_power/1000)*(total_time/3600) # Convert W into kw and s into h\n",
    "idle_gpu_energy_per_thousand_prompts = total_idle_gpu_energy / num_prompts * 10_000\n",
    "\n",
    "print(total_idle_gpu_energy)\n",
    "print(idle_gpu_energy_per_thousand_prompts)\n",
    "\n",
    "gpu_energy_without_idle = gpu_energy - total_idle_gpu_energy\n",
    "gpu_energy_without_idle_per_thousand_prompts = gpu_energy_without_idle / num_prompts * 10_000\n",
    "\n",
    "print(gpu_energy)\n",
    "print(gpu_energy_without_idle_per_thousand_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate emissions per 10,000 prompts\n",
    "emissions_per_thousand_prompts = {\n",
    "    'Total Emissions': total_emissions / num_prompts * 10_000,\n",
    "    'CPU Energy': cpu_energy / num_prompts * 10_000,\n",
    "    'GPU Energy': gpu_energy / num_prompts * 10_000,\n",
    "    'GPU Energy (without idle)': gpu_energy_without_idle_per_thousand_prompts,\n",
    "    'GPU Energy (idle)': idle_gpu_energy_per_thousand_prompts,\n",
    "    'RAM Energy': ram_energy / num_prompts * 10_000,\n",
    "    'Total Energy': total_energy / num_prompts * 10_000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idle GPU Energy per 10.000 prompts: [0.05554152 0.1180922 ]\n",
      "Idle GPU Energy per 10.000 prompts: [0.02197032 0.06244756]\n",
      "GPU Energy without idle per 10.000 prompts: [0.0335712  0.05564464]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Idle GPU Energy per 10.000 prompts: {emissions_per_thousand_prompts['GPU Energy']}\")\n",
    "print(f\"Idle GPU Energy per 10.000 prompts: {idle_gpu_energy_per_thousand_prompts}\")\n",
    "print(f\"GPU Energy without idle per 10.000 prompts: {gpu_energy_without_idle_per_thousand_prompts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total Emissions': array([0.05453253, 0.12855241]), 'CPU Energy': array([0.01017157, 0.02891024]), 'GPU Energy': array([0.05554152, 0.1180922 ]), 'GPU Energy (without idle)': array([0.0335712 , 0.05564464]), 'GPU Energy (idle)': array([0.02197032, 0.06244756]), 'RAM Energy': array([0.0162971, 0.0463245]), 'Total Energy': array([0.08201019, 0.19332693])}\n"
     ]
    }
   ],
   "source": [
    "print(emissions_per_thousand_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine</th>\n",
       "      <th>model_type</th>\n",
       "      <th>parameters</th>\n",
       "      <th>num_prompts</th>\n",
       "      <th>total_time</th>\n",
       "      <th>time_per_prompt</th>\n",
       "      <th>tok_per_sec</th>\n",
       "      <th>total_out_tok</th>\n",
       "      <th>total_in_tok</th>\n",
       "      <th>avg_out_tok</th>\n",
       "      <th>avg_in_tok</th>\n",
       "      <th>actual_emissions_per_10k_prompts</th>\n",
       "      <th>actual_total_energy_per_10k_prompts</th>\n",
       "      <th>actual_cpu_energy_per_10k_prompts</th>\n",
       "      <th>actual_gpu_energy_per_10k_prompts</th>\n",
       "      <th>actual_ram_energy_per_10k_prompts</th>\n",
       "      <th>actual_idle_gpu_energy_per_10k_prompts</th>\n",
       "      <th>actual_non_idle_gpu_energy_per_10k_prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vllm</td>\n",
       "      <td>Llama-3-8B</td>\n",
       "      <td>8</td>\n",
       "      <td>7500</td>\n",
       "      <td>529.641753</td>\n",
       "      <td>0.070619</td>\n",
       "      <td>1013.528479</td>\n",
       "      <td>536807.0</td>\n",
       "      <td>1399950.0</td>\n",
       "      <td>71.574267</td>\n",
       "      <td>186.66</td>\n",
       "      <td>0.054533</td>\n",
       "      <td>0.082010</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.055542</td>\n",
       "      <td>0.016297</td>\n",
       "      <td>0.021970</td>\n",
       "      <td>0.033571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformers</td>\n",
       "      <td>Llama-3-8B</td>\n",
       "      <td>8</td>\n",
       "      <td>7500</td>\n",
       "      <td>1505.432260</td>\n",
       "      <td>0.200724</td>\n",
       "      <td>179.998136</td>\n",
       "      <td>270975.0</td>\n",
       "      <td>1399950.0</td>\n",
       "      <td>36.130000</td>\n",
       "      <td>186.66</td>\n",
       "      <td>0.128552</td>\n",
       "      <td>0.193327</td>\n",
       "      <td>0.028910</td>\n",
       "      <td>0.118092</td>\n",
       "      <td>0.046324</td>\n",
       "      <td>0.062448</td>\n",
       "      <td>0.055645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         engine  model_type  parameters  num_prompts   total_time  \\\n",
       "0          vllm  Llama-3-8B           8         7500   529.641753   \n",
       "1  transformers  Llama-3-8B           8         7500  1505.432260   \n",
       "\n",
       "   time_per_prompt  tok_per_sec  total_out_tok  total_in_tok  avg_out_tok  \\\n",
       "0         0.070619  1013.528479       536807.0     1399950.0    71.574267   \n",
       "1         0.200724   179.998136       270975.0     1399950.0    36.130000   \n",
       "\n",
       "   avg_in_tok  actual_emissions_per_10k_prompts  \\\n",
       "0      186.66                          0.054533   \n",
       "1      186.66                          0.128552   \n",
       "\n",
       "   actual_total_energy_per_10k_prompts  actual_cpu_energy_per_10k_prompts  \\\n",
       "0                             0.082010                           0.010172   \n",
       "1                             0.193327                           0.028910   \n",
       "\n",
       "   actual_gpu_energy_per_10k_prompts  actual_ram_energy_per_10k_prompts  \\\n",
       "0                           0.055542                           0.016297   \n",
       "1                           0.118092                           0.046324   \n",
       "\n",
       "   actual_idle_gpu_energy_per_10k_prompts  \\\n",
       "0                                0.021970   \n",
       "1                                0.062448   \n",
       "\n",
       "   actual_non_idle_gpu_energy_per_10k_prompts  \n",
       "0                                    0.033571  \n",
       "1                                    0.055645  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframe\n",
    "df = pd.DataFrame({\n",
    "    'engine': engine,\n",
    "    'model_type': ['Llama-3-8B', 'Llama-3-8B'],\n",
    "    'parameters': parameters,\n",
    "    'num_prompts': num_prompts,\n",
    "    'total_time': total_time,\n",
    "    'time_per_prompt': time_per_prompt,\n",
    "    'tok_per_sec': tok_per_sec,\n",
    "    'total_out_tok': total_output_tokens,\n",
    "    'total_in_tok': total_input_tokens,\n",
    "    'avg_out_tok': avg_output_tokens,\n",
    "    'avg_in_tok': avg_input_tokens,\n",
    "    'actual_emissions_per_10k_prompts': emissions_per_thousand_prompts['Total Emissions'],\n",
    "    'actual_total_energy_per_10k_prompts': emissions_per_thousand_prompts['Total Energy'],\n",
    "    'actual_cpu_energy_per_10k_prompts': emissions_per_thousand_prompts['CPU Energy'],\n",
    "    'actual_gpu_energy_per_10k_prompts': emissions_per_thousand_prompts['GPU Energy'],\n",
    "    'actual_ram_energy_per_10k_prompts': emissions_per_thousand_prompts['RAM Energy'],\n",
    "    'actual_idle_gpu_energy_per_10k_prompts': emissions_per_thousand_prompts['GPU Energy (idle)'],\n",
    "    'actual_non_idle_gpu_energy_per_10k_prompts': emissions_per_thousand_prompts['GPU Energy (without idle)'],\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the results in a CSV file\n",
    "df.to_csv('results/data/transformers_vs_vllm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
