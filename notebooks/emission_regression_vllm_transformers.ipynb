{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the individual CSV files\n",
    "csv_files_output = {\n",
    "    'vllm': 'emission_data/vllm_meta-llama/Meta-Llama-3.1-8B-Instruct_emission_data.csv',\n",
    "    'transformers': 'emission_data/transformers_meta-llama/Meta-Llama-3.1-8B-Instruct_emission_data.csv',\n",
    "}\n",
    "\n",
    "# Read the emissions data\n",
    "emissions_data = pd.read_csv('emissions_vllm_transformers_llama3_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store metadata\n",
    "total_time = []\n",
    "time_per_prompt = []\n",
    "tok_per_sec = []\n",
    "engine = []\n",
    "parameters = []\n",
    "num_prompts = []\n",
    "total_emissions = []\n",
    "cpu_energy = []\n",
    "gpu_energy = []\n",
    "ram_energy = []\n",
    "total_energy = []\n",
    "total_output_tokens = []\n",
    "total_input_tokens = []\n",
    "avg_input_tokens = []\n",
    "avg_output_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and extract metadata from each CSV file\n",
    "for model, file in csv_files_output.items():\n",
    "    data = pd.read_csv(file)\n",
    "    time = data.loc[data['Metric'] == 'Total Time', 'Value'].values[0]\n",
    "    time_p_prompt = data.loc[data['Metric'] == 'AVG. Time / Prompt', 'Value'].values[0] / 1000 #Time is in ms\n",
    "    tok_p_sec = data.loc[data['Metric'] == 'AVG. Tokens / Second', 'Value'].values[0]\n",
    "    prompts = data.loc[data['Metric'] == 'Total Prompts', 'Value'].values[0]\n",
    "    output_tokens = data.loc[data['Metric'] == 'Total Output Tokens', 'Value'].values[0]\n",
    "    input_tokens = data.loc[data['Metric'] == 'Total Input Tokens', 'Value'].values[0]\n",
    "    avg_i_tok = data.loc[data['Metric'] == 'AVG. Input Tokens / Prompt', 'Value'].values[0]\n",
    "    avg_o_tok = data.loc[data['Metric'] == 'AVG. Output Tokens / Prompt', 'Value'].values[0]\n",
    "    total_time.append(float(time))\n",
    "    time_per_prompt.append(float(time_p_prompt))\n",
    "    tok_per_sec.append(float(tok_p_sec))\n",
    "    parameters.append(8)\n",
    "    num_prompts.append(int(prompts))\n",
    "    engine.append(model)\n",
    "    total_output_tokens.append(float(output_tokens))\n",
    "    total_input_tokens.append(float(input_tokens))\n",
    "    avg_input_tokens.append(float(avg_i_tok))\n",
    "    avg_output_tokens.append(float(avg_o_tok))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract emissions data\n",
    "for idx, model in enumerate(csv_files_output.keys()):\n",
    "    model_emissions = emissions_data\n",
    "    total_emissions.append(model_emissions['emissions'].values[idx])\n",
    "    cpu_energy.append(model_emissions['cpu_energy'].values[idx])\n",
    "    gpu_energy.append(model_emissions['gpu_energy'].values[idx])\n",
    "    ram_energy.append(model_emissions['ram_energy'].values[idx])\n",
    "    total_energy.append(model_emissions['energy_consumed'].values[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0480402278404932, 0.1929542349933592]\n",
      "[0.0092630084421402, 0.0429047904024687]\n",
      "[0.048142913980967, 0.1785292698233014]\n",
      "[0.0148406416413424, 0.0687452567050357]\n",
      "[0.0722465640644497, 0.2901793169308061]\n"
     ]
    }
   ],
   "source": [
    "print(total_emissions)\n",
    "print(cpu_energy)\n",
    "print(gpu_energy)\n",
    "print(ram_energy)\n",
    "print(total_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for regression and visualization\n",
    "total_time = np.array(total_time)\n",
    "time_per_prompt = np.array(time_per_prompt)\n",
    "tok_per_sec = np.array(tok_per_sec)\n",
    "parameters = np.array(parameters)\n",
    "num_prompts = np.array(num_prompts)\n",
    "total_output_tokens = np.array(total_output_tokens)\n",
    "total_input_tokens = np.array(total_input_tokens)\n",
    "avg_input_tokens = np.array(avg_input_tokens)\n",
    "avg_output_tokens = np.array(avg_output_tokens)\n",
    "total_emissions = np.array(total_emissions)\n",
    "cpu_energy = np.array(cpu_energy)\n",
    "gpu_energy = np.array(gpu_energy)\n",
    "ram_energy = np.array(ram_energy)\n",
    "total_energy = np.array(total_energy)\n",
    "engine = np.array(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 643.117311   2978.90883017]\n"
     ]
    }
   ],
   "source": [
    "print(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02000809 0.09267716]\n",
      "[0.02667746 0.12356955]\n",
      "[0.04814291 0.17852927]\n",
      "[0.03751309 0.11446947]\n"
     ]
    }
   ],
   "source": [
    "idle_gpu_power = 28*4 # 28W per GPU, 4 GPUs\n",
    "\n",
    "total_idle_gpu_energy = (idle_gpu_power/1000)*(total_time/3600) # Convert W into kw and s into h\n",
    "idle_gpu_energy_per_thousand_prompts = total_idle_gpu_energy / num_prompts * 10_000\n",
    "\n",
    "print(total_idle_gpu_energy)\n",
    "print(idle_gpu_energy_per_thousand_prompts)\n",
    "\n",
    "gpu_energy_without_idle = gpu_energy - total_idle_gpu_energy\n",
    "gpu_energy_without_idle_per_thousand_prompts = gpu_energy_without_idle / num_prompts * 10_000\n",
    "\n",
    "print(gpu_energy)\n",
    "print(gpu_energy_without_idle_per_thousand_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate emissions per 10,000 prompts\n",
    "emissions_per_thousand_prompts = {\n",
    "    'Total Emissions': total_emissions / num_prompts * 10_000,\n",
    "    'CPU Energy': cpu_energy / num_prompts * 10_000,\n",
    "    'GPU Energy': gpu_energy / num_prompts * 10_000,\n",
    "    'GPU Energy (without idle)': gpu_energy_without_idle_per_thousand_prompts,\n",
    "    'GPU Energy (idle)': idle_gpu_energy_per_thousand_prompts,\n",
    "    'RAM Energy': ram_energy / num_prompts * 10_000,\n",
    "    'Total Energy': total_energy / num_prompts * 10_000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idle GPU Energy per 10.000 prompts: [0.06419055 0.23803903]\n",
      "Idle GPU Energy per 10.000 prompts: [0.02667746 0.12356955]\n",
      "GPU Energy without idle per 10.000 prompts: [0.03751309 0.11446947]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Idle GPU Energy per 10.000 prompts: {emissions_per_thousand_prompts['GPU Energy']}\")\n",
    "print(f\"Idle GPU Energy per 10.000 prompts: {idle_gpu_energy_per_thousand_prompts}\")\n",
    "print(f\"GPU Energy without idle per 10.000 prompts: {gpu_energy_without_idle_per_thousand_prompts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total Emissions': array([0.06405364, 0.25727231]), 'CPU Energy': array([0.01235068, 0.05720639]), 'GPU Energy': array([0.06419055, 0.23803903]), 'GPU Energy (without idle)': array([0.03751309, 0.11446947]), 'GPU Energy (idle)': array([0.02667746, 0.12356955]), 'RAM Energy': array([0.01978752, 0.09166034]), 'Total Energy': array([0.09632875, 0.38690576])}\n"
     ]
    }
   ],
   "source": [
    "print(emissions_per_thousand_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine</th>\n",
       "      <th>model_type</th>\n",
       "      <th>parameters</th>\n",
       "      <th>num_prompts</th>\n",
       "      <th>total_time</th>\n",
       "      <th>time_per_prompt</th>\n",
       "      <th>tok_per_sec</th>\n",
       "      <th>total_out_tok</th>\n",
       "      <th>total_in_tok</th>\n",
       "      <th>avg_out_tok</th>\n",
       "      <th>avg_in_tok</th>\n",
       "      <th>actual_emissions_per_10k_prompts</th>\n",
       "      <th>actual_total_energy_per_10k_prompts</th>\n",
       "      <th>actual_cpu_energy_per_10k_prompts</th>\n",
       "      <th>actual_gpu_energy_per_10k_prompts</th>\n",
       "      <th>actual_ram_energy_per_10k_prompts</th>\n",
       "      <th>actual_idle_gpu_energy_per_10k_prompts</th>\n",
       "      <th>actual_non_idle_gpu_energy_per_10k_prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vllm</td>\n",
       "      <td>Llama-3-8B</td>\n",
       "      <td>8</td>\n",
       "      <td>7500</td>\n",
       "      <td>643.117311</td>\n",
       "      <td>0.085749</td>\n",
       "      <td>1009.821986</td>\n",
       "      <td>649434.0</td>\n",
       "      <td>1549950.0</td>\n",
       "      <td>86.591200</td>\n",
       "      <td>206.66</td>\n",
       "      <td>0.064054</td>\n",
       "      <td>0.096329</td>\n",
       "      <td>0.012351</td>\n",
       "      <td>0.064191</td>\n",
       "      <td>0.019788</td>\n",
       "      <td>0.026677</td>\n",
       "      <td>0.037513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformers</td>\n",
       "      <td>Llama-3-8B</td>\n",
       "      <td>8</td>\n",
       "      <td>7500</td>\n",
       "      <td>2978.908830</td>\n",
       "      <td>0.397188</td>\n",
       "      <td>219.681111</td>\n",
       "      <td>654410.0</td>\n",
       "      <td>1549950.0</td>\n",
       "      <td>87.254667</td>\n",
       "      <td>206.66</td>\n",
       "      <td>0.257272</td>\n",
       "      <td>0.386906</td>\n",
       "      <td>0.057206</td>\n",
       "      <td>0.238039</td>\n",
       "      <td>0.091660</td>\n",
       "      <td>0.123570</td>\n",
       "      <td>0.114469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         engine  model_type  parameters  num_prompts   total_time  \\\n",
       "0          vllm  Llama-3-8B           8         7500   643.117311   \n",
       "1  transformers  Llama-3-8B           8         7500  2978.908830   \n",
       "\n",
       "   time_per_prompt  tok_per_sec  total_out_tok  total_in_tok  avg_out_tok  \\\n",
       "0         0.085749  1009.821986       649434.0     1549950.0    86.591200   \n",
       "1         0.397188   219.681111       654410.0     1549950.0    87.254667   \n",
       "\n",
       "   avg_in_tok  actual_emissions_per_10k_prompts  \\\n",
       "0      206.66                          0.064054   \n",
       "1      206.66                          0.257272   \n",
       "\n",
       "   actual_total_energy_per_10k_prompts  actual_cpu_energy_per_10k_prompts  \\\n",
       "0                             0.096329                           0.012351   \n",
       "1                             0.386906                           0.057206   \n",
       "\n",
       "   actual_gpu_energy_per_10k_prompts  actual_ram_energy_per_10k_prompts  \\\n",
       "0                           0.064191                           0.019788   \n",
       "1                           0.238039                           0.091660   \n",
       "\n",
       "   actual_idle_gpu_energy_per_10k_prompts  \\\n",
       "0                                0.026677   \n",
       "1                                0.123570   \n",
       "\n",
       "   actual_non_idle_gpu_energy_per_10k_prompts  \n",
       "0                                    0.037513  \n",
       "1                                    0.114469  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframe\n",
    "df = pd.DataFrame({\n",
    "    'engine': engine,\n",
    "    'model_type': ['Llama-3-8B', 'Llama-3-8B'],\n",
    "    'parameters': parameters,\n",
    "    'num_prompts': num_prompts,\n",
    "    'total_time': total_time,\n",
    "    'time_per_prompt': time_per_prompt,\n",
    "    'tok_per_sec': tok_per_sec,\n",
    "    'total_out_tok': total_output_tokens,\n",
    "    'total_in_tok': total_input_tokens,\n",
    "    'avg_out_tok': avg_output_tokens,\n",
    "    'avg_in_tok': avg_input_tokens,\n",
    "    'actual_emissions_per_10k_prompts': emissions_per_thousand_prompts['Total Emissions'],\n",
    "    'actual_total_energy_per_10k_prompts': emissions_per_thousand_prompts['Total Energy'],\n",
    "    'actual_cpu_energy_per_10k_prompts': emissions_per_thousand_prompts['CPU Energy'],\n",
    "    'actual_gpu_energy_per_10k_prompts': emissions_per_thousand_prompts['GPU Energy'],\n",
    "    'actual_ram_energy_per_10k_prompts': emissions_per_thousand_prompts['RAM Energy'],\n",
    "    'actual_idle_gpu_energy_per_10k_prompts': emissions_per_thousand_prompts['GPU Energy (idle)'],\n",
    "    'actual_non_idle_gpu_energy_per_10k_prompts': emissions_per_thousand_prompts['GPU Energy (without idle)'],\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the results in a CSV file\n",
    "df.to_csv('results/data/transformers_vs_vllm_llama3_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
