{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the individual CSV files\n",
    "csv_files_output = {\n",
    "    # '70B_8GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-70b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    # '34B_8GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-34b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    # '13B_8GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-13b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    # '7B_8GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-7b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    # '34B_4GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-34b-Instruct-hf_4GPUs_emission_data.csv',\n",
    "    # '13B_4GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-13b-Instruct-hf_4GPUs_emission_data.csv',\n",
    "    # '7B_4GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-7b-Instruct-hf_4GPUs_emission_data.csv',\n",
    "    # '13B_2GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-13b-Instruct-hf_2GPUs_emission_data.csv',\n",
    "    # '7B_2GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-7b-Instruct-hf_2GPUs_emission_data.csv',\n",
    "    # '7B_1GPU': 'emission_data/vLLM_meta-llama/CodeLlama-7b-Instruct-hf_1GPU_emission_data.csv',\n",
    "\n",
    "    '70B_8GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-70b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    '34B_8GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-34b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    '13B_8GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-13b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    '7B_8GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-7b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    '34B_4GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-70b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    '13B_4GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-70b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    '7B_4GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-70b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    '13B_2GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-70b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    '7B_2GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-70b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    '7B_1GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-70b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "}\n",
    "\n",
    "# Read the emissions data\n",
    "emissions_data = pd.read_csv('emissions_params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store metadata\n",
    "total_time = []\n",
    "time_per_prompt = []\n",
    "tok_per_sec = []\n",
    "setup = []\n",
    "parameters = []\n",
    "num_gpus = []\n",
    "num_prompts = []\n",
    "total_emissions = []\n",
    "cpu_energy = []\n",
    "gpu_energy = []\n",
    "ram_energy = []\n",
    "total_energy = []\n",
    "total_output_tokens = []\n",
    "total_input_tokens = []\n",
    "avg_input_tokens = []\n",
    "avg_output_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and extract metadata from each CSV file\n",
    "for model, file in csv_files_output.items():\n",
    "    data = pd.read_csv(file)\n",
    "    time = data.loc[data['Metric'] == 'Total Time', 'Value'].values[0]\n",
    "    time_p_prompt = data.loc[data['Metric'] == 'AVG. Time / Prompt', 'Value'].values[0] / 1000 #Time is in ms\n",
    "    tok_p_sec = data.loc[data['Metric'] == 'AVG. Tokens / Second', 'Value'].values[0]\n",
    "    prompts = data.loc[data['Metric'] == 'Total Prompts', 'Value'].values[0]\n",
    "    output_tokens = data.loc[data['Metric'] == 'Total Output Tokens', 'Value'].values[0]\n",
    "    input_tokens = data.loc[data['Metric'] == 'Total Input Tokens', 'Value'].values[0]\n",
    "    avg_i_tok = data.loc[data['Metric'] == 'AVG. Input Tokens / Prompt', 'Value'].values[0]\n",
    "    avg_o_tok = data.loc[data['Metric'] == 'AVG. Output Tokens / Prompt', 'Value'].values[0]\n",
    "\n",
    "    # Extract parameters and number of GPUs from the key\n",
    "    param_str, gpus_str = model.split('_')\n",
    "    param_value = int(param_str[:-1])  # Remove the 'B' and convert to int\n",
    "    gpus_value = int(gpus_str.split('GPUs')[0])\n",
    "    \n",
    "    parameters.append(param_value)\n",
    "    num_gpus.append(gpus_value)\n",
    "\n",
    "    total_time.append(float(time))\n",
    "    time_per_prompt.append(float(time_p_prompt))\n",
    "    tok_per_sec.append(float(tok_p_sec))\n",
    "\n",
    "    num_prompts.append(int(prompts))\n",
    "    setup.append(model)\n",
    "    total_output_tokens.append(float(output_tokens))\n",
    "    total_input_tokens.append(float(input_tokens))\n",
    "    avg_input_tokens.append(float(avg_i_tok))\n",
    "    avg_output_tokens.append(float(avg_o_tok))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract emissions data\n",
    "for idx, model in enumerate(csv_files_output.keys()):\n",
    "\n",
    "    if idx > 3:\n",
    "        idx = 0\n",
    "\n",
    "    model_emissions = emissions_data\n",
    "    total_emissions.append(model_emissions['emissions'].values[idx])\n",
    "    cpu_energy.append(model_emissions['cpu_energy'].values[idx])\n",
    "    gpu_energy.append(model_emissions['gpu_energy'].values[idx])\n",
    "    ram_energy.append(model_emissions['ram_energy'].values[idx])\n",
    "    total_energy.append(model_emissions['energy_consumed'].values[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8697600057623235, 0.4509315464112079, 0.2388394208735168, 0.1640960954110507, 0.8697600057623235, 0.8697600057623235, 0.8697600057623235, 0.8697600057623235, 0.8697600057623235, 0.8697600057623235]\n",
      "[0.077260215018938, 0.0422043971629308, 0.0223365311098363, 0.0154791704585982, 0.077260215018938, 0.077260215018938, 0.077260215018938, 0.077260215018938, 0.077260215018938, 0.077260215018938]\n",
      "[0.7352734845905394, 0.3652718549561389, 0.1936305076487266, 0.1320215299282504, 0.7352734845905394, 0.7352734845905394, 0.7352734845905394, 0.7352734845905394, 0.7352734845905394, 0.7352734845905394]\n",
      "[0.4954778315939251, 0.2706690507018804, 0.1432179255290137, 0.0992795419801035, 0.4954778315939251, 0.4954778315939251, 0.4954778315939251, 0.4954778315939251, 0.4954778315939251, 0.4954778315939251]\n",
      "[1.3080115312034024, 0.6781453028209502, 0.3591849642875767, 0.2467802423669523, 1.3080115312034024, 1.3080115312034024, 1.3080115312034024, 1.3080115312034024, 1.3080115312034024, 1.3080115312034024]\n"
     ]
    }
   ],
   "source": [
    "print(total_emissions)\n",
    "print(cpu_energy)\n",
    "print(gpu_energy)\n",
    "print(ram_energy)\n",
    "print(total_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for regression and visualization\n",
    "total_time = np.array(total_time)\n",
    "time_per_prompt = np.array(time_per_prompt)\n",
    "tok_per_sec = np.array(tok_per_sec)\n",
    "parameters = np.array(parameters)\n",
    "num_gpus = np.array(num_gpus)\n",
    "num_prompts = np.array(num_prompts)\n",
    "total_output_tokens = np.array(total_output_tokens)\n",
    "total_input_tokens = np.array(total_input_tokens)\n",
    "avg_input_tokens = np.array(avg_input_tokens)\n",
    "avg_output_tokens = np.array(avg_output_tokens)\n",
    "total_emissions = np.array(total_emissions)\n",
    "cpu_energy = np.array(cpu_energy)\n",
    "gpu_energy = np.array(gpu_energy)\n",
    "ram_energy = np.array(ram_energy)\n",
    "total_energy = np.array(total_energy)\n",
    "setup = np.array(setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5364.2286284  2930.25584149 1550.81419516 1074.69416142 5364.2286284\n",
      " 5364.2286284  5364.2286284  5364.2286284  5364.2286284  5364.2286284 ]\n"
     ]
    }
   ],
   "source": [
    "print(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33377423 0.18232703 0.09649511 0.06686986 0.16688711 0.16688711\n",
      " 0.16688711 0.08344356 0.08344356 0.04172178]\n",
      "[44.5032301  24.31027068 12.86601406  8.91598119 22.25161505 22.25161505\n",
      " 22.25161505 11.12580753 11.12580753  5.56290376]\n",
      "[0.73527348 0.36527185 0.19363051 0.13202153 0.73527348 0.73527348\n",
      " 0.73527348 0.73527348 0.73527348 0.73527348]\n",
      "[53.53323451 24.39264331 12.95138696  8.68688947 75.78484956 75.78484956\n",
      " 75.78484956 86.91065709 86.91065709 92.47356085]\n"
     ]
    }
   ],
   "source": [
    "idle_gpu_power = 28*num_gpus # 28W per GPU\n",
    "\n",
    "total_idle_gpu_energy = (idle_gpu_power/1000)*(total_time/3600) # Convert W into kw and s into h\n",
    "idle_gpu_energy_per_million_prompts = total_idle_gpu_energy / num_prompts * 1_000_000\n",
    "\n",
    "print(total_idle_gpu_energy)\n",
    "print(idle_gpu_energy_per_million_prompts)\n",
    "\n",
    "gpu_energy_without_idle = gpu_energy - total_idle_gpu_energy\n",
    "gpu_energy_without_idle_per_million_prompts = gpu_energy_without_idle / num_prompts * 1_000_000\n",
    "\n",
    "print(gpu_energy)\n",
    "print(gpu_energy_without_idle_per_million_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate emissions per 1,000,000 prompts\n",
    "emissions_per_million_prompts = {\n",
    "    'Total Emissions': total_emissions / num_prompts * 1_000_000,\n",
    "    'CPU Energy': cpu_energy / num_prompts * 1_000_000,\n",
    "    'GPU Energy': gpu_energy / num_prompts * 1_000_000,\n",
    "    'GPU Energy (without idle)': gpu_energy_without_idle_per_million_prompts,\n",
    "    'GPU Energy (idle)': idle_gpu_energy_per_million_prompts,\n",
    "    'RAM Energy': ram_energy / num_prompts * 1_000_000,\n",
    "    'Total Energy': total_energy / num_prompts * 1_000_000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idle GPU Energy per 1.000.000 prompts: [98.03646461 48.70291399 25.81740102 17.60287066 98.03646461 98.03646461\n",
      " 98.03646461 98.03646461 98.03646461 98.03646461]\n",
      "Idle GPU Energy per 1.000.000 prompts: [44.5032301  24.31027068 12.86601406  8.91598119 22.25161505 22.25161505\n",
      " 22.25161505 11.12580753 11.12580753  5.56290376]\n",
      "GPU Energy without idle per 1.000.000 prompts: [53.53323451 24.39264331 12.95138696  8.68688947 75.78484956 75.78484956\n",
      " 75.78484956 86.91065709 86.91065709 92.47356085]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Idle GPU Energy per 1.000.000 prompts: {emissions_per_million_prompts['GPU Energy']}\")\n",
    "print(f\"Idle GPU Energy per 1.000.000 prompts: {idle_gpu_energy_per_million_prompts}\")\n",
    "print(f\"GPU Energy without idle per 1.000.000 prompts: {gpu_energy_without_idle_per_million_prompts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total Emissions': array([115.96800077,  60.12420619,  31.84525612,  21.87947939,\n",
      "       115.96800077, 115.96800077, 115.96800077, 115.96800077,\n",
      "       115.96800077, 115.96800077]), 'CPU Energy': array([10.301362  ,  5.62725296,  2.97820415,  2.06388939, 10.301362  ,\n",
      "       10.301362  , 10.301362  , 10.301362  , 10.301362  , 10.301362  ]), 'GPU Energy': array([98.03646461, 48.70291399, 25.81740102, 17.60287066, 98.03646461,\n",
      "       98.03646461, 98.03646461, 98.03646461, 98.03646461, 98.03646461]), 'GPU Energy (without idle)': array([53.53323451, 24.39264331, 12.95138696,  8.68688947, 75.78484956,\n",
      "       75.78484956, 75.78484956, 86.91065709, 86.91065709, 92.47356085]), 'GPU Energy (idle)': array([44.5032301 , 24.31027068, 12.86601406,  8.91598119, 22.25161505,\n",
      "       22.25161505, 22.25161505, 11.12580753, 11.12580753,  5.56290376]), 'RAM Energy': array([66.06371088, 36.08920676, 19.0957234 , 13.23727226, 66.06371088,\n",
      "       66.06371088, 66.06371088, 66.06371088, 66.06371088, 66.06371088]), 'Total Energy': array([174.40153749,  90.41937371,  47.89132857,  32.90403232,\n",
      "       174.40153749, 174.40153749, 174.40153749, 174.40153749,\n",
      "       174.40153749, 174.40153749])}\n"
     ]
    }
   ],
   "source": [
    "print(emissions_per_million_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_setup</th>\n",
       "      <th>parameters</th>\n",
       "      <th>num_gpus</th>\n",
       "      <th>num_prompts</th>\n",
       "      <th>total_time</th>\n",
       "      <th>time_per_prompt</th>\n",
       "      <th>tok_per_sec</th>\n",
       "      <th>total_out_tok</th>\n",
       "      <th>total_in_tok</th>\n",
       "      <th>avg_out_tok</th>\n",
       "      <th>avg_in_tok</th>\n",
       "      <th>emissions_per_1M_prompts</th>\n",
       "      <th>total_energy_per_1M_prompts</th>\n",
       "      <th>cpu_energy_per_1M_prompts</th>\n",
       "      <th>gpu_energy_per_1M_prompts</th>\n",
       "      <th>ram_energy_per_1M_prompts</th>\n",
       "      <th>idle_gpu_energy_per_1M_prompts</th>\n",
       "      <th>non_idle_gpu_energy_per_1M_prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70B_8GPUs</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>7500</td>\n",
       "      <td>5364.228628</td>\n",
       "      <td>0.715230</td>\n",
       "      <td>215.326206</td>\n",
       "      <td>1155059.0</td>\n",
       "      <td>1905000.0</td>\n",
       "      <td>154.007867</td>\n",
       "      <td>254.0</td>\n",
       "      <td>115.968001</td>\n",
       "      <td>174.401537</td>\n",
       "      <td>10.301362</td>\n",
       "      <td>98.036465</td>\n",
       "      <td>66.063711</td>\n",
       "      <td>44.503230</td>\n",
       "      <td>53.533235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34B_8GPUs</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>7500</td>\n",
       "      <td>2930.255841</td>\n",
       "      <td>0.390701</td>\n",
       "      <td>334.550651</td>\n",
       "      <td>980319.0</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>130.709200</td>\n",
       "      <td>256.0</td>\n",
       "      <td>60.124206</td>\n",
       "      <td>90.419374</td>\n",
       "      <td>5.627253</td>\n",
       "      <td>48.702914</td>\n",
       "      <td>36.089207</td>\n",
       "      <td>24.310271</td>\n",
       "      <td>24.392643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13B_8GPUs</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>7500</td>\n",
       "      <td>1550.814195</td>\n",
       "      <td>0.206775</td>\n",
       "      <td>554.112158</td>\n",
       "      <td>859325.0</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>114.576667</td>\n",
       "      <td>256.0</td>\n",
       "      <td>31.845256</td>\n",
       "      <td>47.891329</td>\n",
       "      <td>2.978204</td>\n",
       "      <td>25.817401</td>\n",
       "      <td>19.095723</td>\n",
       "      <td>12.866014</td>\n",
       "      <td>12.951387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7B_8GPUs</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7500</td>\n",
       "      <td>1074.694161</td>\n",
       "      <td>0.143293</td>\n",
       "      <td>921.779456</td>\n",
       "      <td>990631.0</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>132.084133</td>\n",
       "      <td>256.0</td>\n",
       "      <td>21.879479</td>\n",
       "      <td>32.904032</td>\n",
       "      <td>2.063889</td>\n",
       "      <td>17.602871</td>\n",
       "      <td>13.237272</td>\n",
       "      <td>8.915981</td>\n",
       "      <td>8.686889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34B_4GPUs</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>7500</td>\n",
       "      <td>5364.228628</td>\n",
       "      <td>0.715230</td>\n",
       "      <td>215.326206</td>\n",
       "      <td>1155059.0</td>\n",
       "      <td>1905000.0</td>\n",
       "      <td>154.007867</td>\n",
       "      <td>254.0</td>\n",
       "      <td>115.968001</td>\n",
       "      <td>174.401537</td>\n",
       "      <td>10.301362</td>\n",
       "      <td>98.036465</td>\n",
       "      <td>66.063711</td>\n",
       "      <td>22.251615</td>\n",
       "      <td>75.784850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13B_4GPUs</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>7500</td>\n",
       "      <td>5364.228628</td>\n",
       "      <td>0.715230</td>\n",
       "      <td>215.326206</td>\n",
       "      <td>1155059.0</td>\n",
       "      <td>1905000.0</td>\n",
       "      <td>154.007867</td>\n",
       "      <td>254.0</td>\n",
       "      <td>115.968001</td>\n",
       "      <td>174.401537</td>\n",
       "      <td>10.301362</td>\n",
       "      <td>98.036465</td>\n",
       "      <td>66.063711</td>\n",
       "      <td>22.251615</td>\n",
       "      <td>75.784850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7B_4GPUs</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7500</td>\n",
       "      <td>5364.228628</td>\n",
       "      <td>0.715230</td>\n",
       "      <td>215.326206</td>\n",
       "      <td>1155059.0</td>\n",
       "      <td>1905000.0</td>\n",
       "      <td>154.007867</td>\n",
       "      <td>254.0</td>\n",
       "      <td>115.968001</td>\n",
       "      <td>174.401537</td>\n",
       "      <td>10.301362</td>\n",
       "      <td>98.036465</td>\n",
       "      <td>66.063711</td>\n",
       "      <td>22.251615</td>\n",
       "      <td>75.784850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13B_2GPUs</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7500</td>\n",
       "      <td>5364.228628</td>\n",
       "      <td>0.715230</td>\n",
       "      <td>215.326206</td>\n",
       "      <td>1155059.0</td>\n",
       "      <td>1905000.0</td>\n",
       "      <td>154.007867</td>\n",
       "      <td>254.0</td>\n",
       "      <td>115.968001</td>\n",
       "      <td>174.401537</td>\n",
       "      <td>10.301362</td>\n",
       "      <td>98.036465</td>\n",
       "      <td>66.063711</td>\n",
       "      <td>11.125808</td>\n",
       "      <td>86.910657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7B_2GPUs</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7500</td>\n",
       "      <td>5364.228628</td>\n",
       "      <td>0.715230</td>\n",
       "      <td>215.326206</td>\n",
       "      <td>1155059.0</td>\n",
       "      <td>1905000.0</td>\n",
       "      <td>154.007867</td>\n",
       "      <td>254.0</td>\n",
       "      <td>115.968001</td>\n",
       "      <td>174.401537</td>\n",
       "      <td>10.301362</td>\n",
       "      <td>98.036465</td>\n",
       "      <td>66.063711</td>\n",
       "      <td>11.125808</td>\n",
       "      <td>86.910657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7B_1GPUs</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7500</td>\n",
       "      <td>5364.228628</td>\n",
       "      <td>0.715230</td>\n",
       "      <td>215.326206</td>\n",
       "      <td>1155059.0</td>\n",
       "      <td>1905000.0</td>\n",
       "      <td>154.007867</td>\n",
       "      <td>254.0</td>\n",
       "      <td>115.968001</td>\n",
       "      <td>174.401537</td>\n",
       "      <td>10.301362</td>\n",
       "      <td>98.036465</td>\n",
       "      <td>66.063711</td>\n",
       "      <td>5.562904</td>\n",
       "      <td>92.473561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_setup  parameters  num_gpus  num_prompts   total_time  \\\n",
       "0   70B_8GPUs          70         8         7500  5364.228628   \n",
       "1   34B_8GPUs          34         8         7500  2930.255841   \n",
       "2   13B_8GPUs          13         8         7500  1550.814195   \n",
       "3    7B_8GPUs           7         8         7500  1074.694161   \n",
       "4   34B_4GPUs          34         4         7500  5364.228628   \n",
       "5   13B_4GPUs          13         4         7500  5364.228628   \n",
       "6    7B_4GPUs           7         4         7500  5364.228628   \n",
       "7   13B_2GPUs          13         2         7500  5364.228628   \n",
       "8    7B_2GPUs           7         2         7500  5364.228628   \n",
       "9    7B_1GPUs           7         1         7500  5364.228628   \n",
       "\n",
       "   time_per_prompt  tok_per_sec  total_out_tok  total_in_tok  avg_out_tok  \\\n",
       "0         0.715230   215.326206      1155059.0     1905000.0   154.007867   \n",
       "1         0.390701   334.550651       980319.0     1920000.0   130.709200   \n",
       "2         0.206775   554.112158       859325.0     1920000.0   114.576667   \n",
       "3         0.143293   921.779456       990631.0     1920000.0   132.084133   \n",
       "4         0.715230   215.326206      1155059.0     1905000.0   154.007867   \n",
       "5         0.715230   215.326206      1155059.0     1905000.0   154.007867   \n",
       "6         0.715230   215.326206      1155059.0     1905000.0   154.007867   \n",
       "7         0.715230   215.326206      1155059.0     1905000.0   154.007867   \n",
       "8         0.715230   215.326206      1155059.0     1905000.0   154.007867   \n",
       "9         0.715230   215.326206      1155059.0     1905000.0   154.007867   \n",
       "\n",
       "   avg_in_tok  emissions_per_1M_prompts  total_energy_per_1M_prompts  \\\n",
       "0       254.0                115.968001                   174.401537   \n",
       "1       256.0                 60.124206                    90.419374   \n",
       "2       256.0                 31.845256                    47.891329   \n",
       "3       256.0                 21.879479                    32.904032   \n",
       "4       254.0                115.968001                   174.401537   \n",
       "5       254.0                115.968001                   174.401537   \n",
       "6       254.0                115.968001                   174.401537   \n",
       "7       254.0                115.968001                   174.401537   \n",
       "8       254.0                115.968001                   174.401537   \n",
       "9       254.0                115.968001                   174.401537   \n",
       "\n",
       "   cpu_energy_per_1M_prompts  gpu_energy_per_1M_prompts  \\\n",
       "0                  10.301362                  98.036465   \n",
       "1                   5.627253                  48.702914   \n",
       "2                   2.978204                  25.817401   \n",
       "3                   2.063889                  17.602871   \n",
       "4                  10.301362                  98.036465   \n",
       "5                  10.301362                  98.036465   \n",
       "6                  10.301362                  98.036465   \n",
       "7                  10.301362                  98.036465   \n",
       "8                  10.301362                  98.036465   \n",
       "9                  10.301362                  98.036465   \n",
       "\n",
       "   ram_energy_per_1M_prompts  idle_gpu_energy_per_1M_prompts  \\\n",
       "0                  66.063711                       44.503230   \n",
       "1                  36.089207                       24.310271   \n",
       "2                  19.095723                       12.866014   \n",
       "3                  13.237272                        8.915981   \n",
       "4                  66.063711                       22.251615   \n",
       "5                  66.063711                       22.251615   \n",
       "6                  66.063711                       22.251615   \n",
       "7                  66.063711                       11.125808   \n",
       "8                  66.063711                       11.125808   \n",
       "9                  66.063711                        5.562904   \n",
       "\n",
       "   non_idle_gpu_energy_per_1M_prompts  \n",
       "0                           53.533235  \n",
       "1                           24.392643  \n",
       "2                           12.951387  \n",
       "3                            8.686889  \n",
       "4                           75.784850  \n",
       "5                           75.784850  \n",
       "6                           75.784850  \n",
       "7                           86.910657  \n",
       "8                           86.910657  \n",
       "9                           92.473561  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframe\n",
    "df = pd.DataFrame({\n",
    "    'model_setup': setup,\n",
    "    'parameters': parameters,\n",
    "    'num_gpus': num_gpus,\n",
    "    'num_prompts': num_prompts,\n",
    "    'total_time': total_time,\n",
    "    'time_per_prompt': time_per_prompt,\n",
    "    'tok_per_sec': tok_per_sec,\n",
    "    'total_out_tok': total_output_tokens,\n",
    "    'total_in_tok': total_input_tokens,\n",
    "    'avg_out_tok': avg_output_tokens,\n",
    "    'avg_in_tok': avg_input_tokens,\n",
    "    'emissions_per_1M_prompts': emissions_per_million_prompts['Total Emissions'],\n",
    "    'total_energy_per_1M_prompts': emissions_per_million_prompts['Total Energy'],\n",
    "    'cpu_energy_per_1M_prompts': emissions_per_million_prompts['CPU Energy'],\n",
    "    'gpu_energy_per_1M_prompts': emissions_per_million_prompts['GPU Energy'],\n",
    "    'ram_energy_per_1M_prompts': emissions_per_million_prompts['RAM Energy'],\n",
    "    'idle_gpu_energy_per_1M_prompts': emissions_per_million_prompts['GPU Energy (idle)'],\n",
    "    'non_idle_gpu_energy_per_1M_prompts': emissions_per_million_prompts['GPU Energy (without idle)'],\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the results in a CSV file\n",
    "df.to_csv('results/data/params_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
