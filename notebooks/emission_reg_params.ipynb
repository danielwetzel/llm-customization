{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the individual CSV files\n",
    "csv_files_output = {\n",
    "    '70B_8GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-70b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    '34B_8GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-34b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    '13B_8GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-13b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    '7B_8GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-7b-Instruct-hf_8GPUs_emission_data.csv',\n",
    "    '34B_4GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-34b-Instruct-hf_4GPUs_emission_data.csv',\n",
    "    '13B_4GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-13b-Instruct-hf_4GPUs_emission_data.csv',\n",
    "    '7B_4GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-7b-Instruct-hf_4GPUs_emission_data.csv',\n",
    "    '7B_1GPUs': 'emission_data/vLLM_meta-llama/CodeLlama-7b-Instruct-hf_1GPUs_emission_data.csv',\n",
    "}\n",
    "\n",
    "# Read the emissions data\n",
    "emissions_data = pd.read_csv('emissions_params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store metadata\n",
    "total_time = []\n",
    "time_per_prompt = []\n",
    "tok_per_sec = []\n",
    "setup = []\n",
    "parameters = []\n",
    "num_gpus = []\n",
    "num_prompts = []\n",
    "total_emissions = []\n",
    "cpu_energy = []\n",
    "gpu_energy = []\n",
    "ram_energy = []\n",
    "total_energy = []\n",
    "total_output_tokens = []\n",
    "total_input_tokens = []\n",
    "avg_input_tokens = []\n",
    "avg_output_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and extract metadata from each CSV file\n",
    "for model, file in csv_files_output.items():\n",
    "    data = pd.read_csv(file)\n",
    "    time = data.loc[data['Metric'] == 'Total Time', 'Value'].values[0]\n",
    "    time_p_prompt = data.loc[data['Metric'] == 'AVG. Time / Prompt', 'Value'].values[0] / 1000 #Time is in ms\n",
    "    tok_p_sec = data.loc[data['Metric'] == 'AVG. Tokens / Second', 'Value'].values[0]\n",
    "    prompts = data.loc[data['Metric'] == 'Total Prompts', 'Value'].values[0]\n",
    "    output_tokens = data.loc[data['Metric'] == 'Total Output Tokens', 'Value'].values[0]\n",
    "    input_tokens = data.loc[data['Metric'] == 'Total Input Tokens', 'Value'].values[0]\n",
    "    avg_i_tok = data.loc[data['Metric'] == 'AVG. Input Tokens / Prompt', 'Value'].values[0]\n",
    "    avg_o_tok = data.loc[data['Metric'] == 'AVG. Output Tokens / Prompt', 'Value'].values[0]\n",
    "\n",
    "    # Extract parameters and number of GPUs from the key\n",
    "    param_str, gpus_str = model.split('_')\n",
    "    param_value = int(param_str[:-1])  # Remove the 'B' and convert to int\n",
    "    gpus_value = int(gpus_str.split('GPUs')[0])\n",
    "    \n",
    "    parameters.append(param_value)\n",
    "    num_gpus.append(gpus_value)\n",
    "\n",
    "    total_time.append(float(time))\n",
    "    time_per_prompt.append(float(time_p_prompt))\n",
    "    tok_per_sec.append(float(tok_p_sec))\n",
    "\n",
    "    num_prompts.append(int(prompts))\n",
    "    setup.append(model)\n",
    "    total_output_tokens.append(float(output_tokens))\n",
    "    total_input_tokens.append(float(input_tokens))\n",
    "    avg_input_tokens.append(float(avg_i_tok))\n",
    "    avg_output_tokens.append(float(avg_o_tok))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract emissions data\n",
    "for idx, model in enumerate(csv_files_output.keys()):\n",
    "\n",
    "    model_emissions = emissions_data\n",
    "    total_emissions.append(model_emissions['emissions'].values[idx])\n",
    "    cpu_energy.append(model_emissions['cpu_energy'].values[idx])\n",
    "    gpu_energy.append(model_emissions['gpu_energy'].values[idx])\n",
    "    ram_energy.append(model_emissions['ram_energy'].values[idx])\n",
    "    total_energy.append(model_emissions['energy_consumed'].values[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8697600057623235, 0.4509315464112079, 0.2388394208735168, 0.1640960954110507, 0.1898612653772712, 0.1109668080551995, 0.0756439920633987, 0.0756439920633987]\n",
      "[0.077260215018938, 0.0422043971629308, 0.0223365311098363, 0.0154791704585982, 0.0330105411355627, 0.0192068019948866, 0.013490448976222, 0.013490448976222]\n",
      "[0.7352734845905394, 0.3652718549561389, 0.1936305076487266, 0.1320215299282504, 0.199628528919362, 0.1169004674258546, 0.0786555925022014, 0.0786555925022014]\n",
      "[0.4954778315939251, 0.2706690507018804, 0.1432179255290137, 0.0992795419801035, 0.0528888029181205, 0.0307730924669254, 0.0216131716719476, 0.0216131716719476]\n",
      "[1.3080115312034024, 0.6781453028209502, 0.3591849642875767, 0.2467802423669523, 0.2855278729730455, 0.1668803618876667, 0.1137592131503711, 0.1137592131503711]\n"
     ]
    }
   ],
   "source": [
    "print(total_emissions)\n",
    "print(cpu_energy)\n",
    "print(gpu_energy)\n",
    "print(ram_energy)\n",
    "print(total_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for regression and visualization\n",
    "total_time = np.array(total_time)\n",
    "time_per_prompt = np.array(time_per_prompt)\n",
    "tok_per_sec = np.array(tok_per_sec)\n",
    "parameters = np.array(parameters)\n",
    "num_gpus = np.array(num_gpus)\n",
    "num_prompts = np.array(num_prompts)\n",
    "total_output_tokens = np.array(total_output_tokens)\n",
    "total_input_tokens = np.array(total_input_tokens)\n",
    "avg_input_tokens = np.array(avg_input_tokens)\n",
    "avg_output_tokens = np.array(avg_output_tokens)\n",
    "total_emissions = np.array(total_emissions)\n",
    "cpu_energy = np.array(cpu_energy)\n",
    "gpu_energy = np.array(gpu_energy)\n",
    "ram_energy = np.array(ram_energy)\n",
    "total_energy = np.array(total_energy)\n",
    "setup = np.array(setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5364.2286284  2930.25584149 1550.81419516 1074.69416142 2291.93837547\n",
      " 1333.53209519  936.62999272  936.62999272]\n"
     ]
    }
   ],
   "source": [
    "print(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33377423 0.18232703 0.09649511 0.06686986 0.07130475 0.04148767\n",
      " 0.0291396  0.0072849 ]\n",
      "[44.5032301  24.31027068 12.86601406  8.91598119  9.50729993  5.53168869\n",
      "  3.88527997  0.97131999]\n",
      "[0.73527348 0.36527185 0.19363051 0.13202153 0.19962853 0.11690047\n",
      " 0.07865559 0.07865559]\n",
      "[53.53323451 24.39264331 12.95138696  8.68688947 17.10983726 10.0550403\n",
      "  6.60213236  9.51609234]\n"
     ]
    }
   ],
   "source": [
    "idle_gpu_power = 28*num_gpus # 28W per GPU\n",
    "\n",
    "total_idle_gpu_energy = (idle_gpu_power/1000)*(total_time/3600) # Convert W into kw and s into h\n",
    "idle_gpu_energy_per_million_prompts = total_idle_gpu_energy / num_prompts * 1_000_000\n",
    "\n",
    "print(total_idle_gpu_energy)\n",
    "print(idle_gpu_energy_per_million_prompts)\n",
    "\n",
    "gpu_energy_without_idle = gpu_energy - total_idle_gpu_energy\n",
    "gpu_energy_without_idle_per_million_prompts = gpu_energy_without_idle / num_prompts * 1_000_000\n",
    "\n",
    "print(gpu_energy)\n",
    "print(gpu_energy_without_idle_per_million_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate emissions per 1,000,000 prompts\n",
    "emissions_per_million_prompts = {\n",
    "    'Total Emissions': total_emissions / num_prompts * 1_000_000,\n",
    "    'CPU Energy': cpu_energy / num_prompts * 1_000_000,\n",
    "    'GPU Energy': gpu_energy / num_prompts * 1_000_000,\n",
    "    'GPU Energy (without idle)': gpu_energy_without_idle_per_million_prompts,\n",
    "    'GPU Energy (idle)': idle_gpu_energy_per_million_prompts,\n",
    "    'RAM Energy': ram_energy / num_prompts * 1_000_000,\n",
    "    'Total Energy': total_energy / num_prompts * 1_000_000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idle GPU Energy per 1.000.000 prompts: [98.03646461 48.70291399 25.81740102 17.60287066 26.61713719 15.58672899\n",
      " 10.48741233 10.48741233]\n",
      "Idle GPU Energy per 1.000.000 prompts: [44.5032301  24.31027068 12.86601406  8.91598119  9.50729993  5.53168869\n",
      "  3.88527997  0.97131999]\n",
      "GPU Energy without idle per 1.000.000 prompts: [53.53323451 24.39264331 12.95138696  8.68688947 17.10983726 10.0550403\n",
      "  6.60213236  9.51609234]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Idle GPU Energy per 1.000.000 prompts: {emissions_per_million_prompts['GPU Energy']}\")\n",
    "print(f\"Idle GPU Energy per 1.000.000 prompts: {idle_gpu_energy_per_million_prompts}\")\n",
    "print(f\"GPU Energy without idle per 1.000.000 prompts: {gpu_energy_without_idle_per_million_prompts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total Emissions': array([115.96800077,  60.12420619,  31.84525612,  21.87947939,\n",
      "        25.31483538,  14.79557441,  10.08586561,  10.08586561]), 'CPU Energy': array([10.301362  ,  5.62725296,  2.97820415,  2.06388939,  4.40140548,\n",
      "        2.56090693,  1.79872653,  1.79872653]), 'GPU Energy': array([98.03646461, 48.70291399, 25.81740102, 17.60287066, 26.61713719,\n",
      "       15.58672899, 10.48741233, 10.48741233]), 'GPU Energy (without idle)': array([53.53323451, 24.39264331, 12.95138696,  8.68688947, 17.10983726,\n",
      "       10.0550403 ,  6.60213236,  9.51609234]), 'GPU Energy (idle)': array([44.5032301 , 24.31027068, 12.86601406,  8.91598119,  9.50729993,\n",
      "        5.53168869,  3.88527997,  0.97131999]), 'RAM Energy': array([66.06371088, 36.08920676, 19.0957234 , 13.23727226,  7.05184039,\n",
      "        4.103079  ,  2.88175622,  2.88175622]), 'Total Energy': array([174.40153749,  90.41937371,  47.89132857,  32.90403232,\n",
      "        38.07038306,  22.25071492,  15.16789509,  15.16789509])}\n"
     ]
    }
   ],
   "source": [
    "print(emissions_per_million_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_setup</th>\n",
       "      <th>parameters</th>\n",
       "      <th>num_gpus</th>\n",
       "      <th>num_prompts</th>\n",
       "      <th>total_time</th>\n",
       "      <th>time_per_prompt</th>\n",
       "      <th>tok_per_sec</th>\n",
       "      <th>total_out_tok</th>\n",
       "      <th>total_in_tok</th>\n",
       "      <th>avg_out_tok</th>\n",
       "      <th>avg_in_tok</th>\n",
       "      <th>emissions_per_1M_prompts</th>\n",
       "      <th>total_energy_per_1M_prompts</th>\n",
       "      <th>cpu_energy_per_1M_prompts</th>\n",
       "      <th>gpu_energy_per_1M_prompts</th>\n",
       "      <th>ram_energy_per_1M_prompts</th>\n",
       "      <th>idle_gpu_energy_per_1M_prompts</th>\n",
       "      <th>non_idle_gpu_energy_per_1M_prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70B_8GPUs</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>7500</td>\n",
       "      <td>5364.228628</td>\n",
       "      <td>0.715230</td>\n",
       "      <td>215.326206</td>\n",
       "      <td>1155059.0</td>\n",
       "      <td>1905000.0</td>\n",
       "      <td>154.007867</td>\n",
       "      <td>254.0</td>\n",
       "      <td>115.968001</td>\n",
       "      <td>174.401537</td>\n",
       "      <td>10.301362</td>\n",
       "      <td>98.036465</td>\n",
       "      <td>66.063711</td>\n",
       "      <td>44.503230</td>\n",
       "      <td>53.533235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34B_8GPUs</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>7500</td>\n",
       "      <td>2930.255841</td>\n",
       "      <td>0.390701</td>\n",
       "      <td>334.550651</td>\n",
       "      <td>980319.0</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>130.709200</td>\n",
       "      <td>256.0</td>\n",
       "      <td>60.124206</td>\n",
       "      <td>90.419374</td>\n",
       "      <td>5.627253</td>\n",
       "      <td>48.702914</td>\n",
       "      <td>36.089207</td>\n",
       "      <td>24.310271</td>\n",
       "      <td>24.392643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13B_8GPUs</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>7500</td>\n",
       "      <td>1550.814195</td>\n",
       "      <td>0.206775</td>\n",
       "      <td>554.112158</td>\n",
       "      <td>859325.0</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>114.576667</td>\n",
       "      <td>256.0</td>\n",
       "      <td>31.845256</td>\n",
       "      <td>47.891329</td>\n",
       "      <td>2.978204</td>\n",
       "      <td>25.817401</td>\n",
       "      <td>19.095723</td>\n",
       "      <td>12.866014</td>\n",
       "      <td>12.951387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7B_8GPUs</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7500</td>\n",
       "      <td>1074.694161</td>\n",
       "      <td>0.143293</td>\n",
       "      <td>921.779456</td>\n",
       "      <td>990631.0</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>132.084133</td>\n",
       "      <td>256.0</td>\n",
       "      <td>21.879479</td>\n",
       "      <td>32.904032</td>\n",
       "      <td>2.063889</td>\n",
       "      <td>17.602871</td>\n",
       "      <td>13.237272</td>\n",
       "      <td>8.915981</td>\n",
       "      <td>8.686889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34B_4GPUs</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>7500</td>\n",
       "      <td>2291.938375</td>\n",
       "      <td>0.305592</td>\n",
       "      <td>427.230073</td>\n",
       "      <td>979185.0</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>130.558000</td>\n",
       "      <td>256.0</td>\n",
       "      <td>25.314835</td>\n",
       "      <td>38.070383</td>\n",
       "      <td>4.401405</td>\n",
       "      <td>26.617137</td>\n",
       "      <td>7.051840</td>\n",
       "      <td>9.507300</td>\n",
       "      <td>17.109837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13B_4GPUs</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>7500</td>\n",
       "      <td>1333.532095</td>\n",
       "      <td>0.177804</td>\n",
       "      <td>648.803282</td>\n",
       "      <td>865200.0</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>115.360000</td>\n",
       "      <td>256.0</td>\n",
       "      <td>14.795574</td>\n",
       "      <td>22.250715</td>\n",
       "      <td>2.560907</td>\n",
       "      <td>15.586729</td>\n",
       "      <td>4.103079</td>\n",
       "      <td>5.531689</td>\n",
       "      <td>10.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7B_4GPUs</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7500</td>\n",
       "      <td>936.629993</td>\n",
       "      <td>0.124884</td>\n",
       "      <td>1057.411152</td>\n",
       "      <td>990403.0</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>132.053733</td>\n",
       "      <td>256.0</td>\n",
       "      <td>10.085866</td>\n",
       "      <td>15.167895</td>\n",
       "      <td>1.798727</td>\n",
       "      <td>10.487412</td>\n",
       "      <td>2.881756</td>\n",
       "      <td>3.885280</td>\n",
       "      <td>6.602132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7B_1GPUs</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7500</td>\n",
       "      <td>936.629993</td>\n",
       "      <td>0.124884</td>\n",
       "      <td>1057.411152</td>\n",
       "      <td>990403.0</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>132.053733</td>\n",
       "      <td>256.0</td>\n",
       "      <td>10.085866</td>\n",
       "      <td>15.167895</td>\n",
       "      <td>1.798727</td>\n",
       "      <td>10.487412</td>\n",
       "      <td>2.881756</td>\n",
       "      <td>0.971320</td>\n",
       "      <td>9.516092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_setup  parameters  num_gpus  num_prompts   total_time  \\\n",
       "0   70B_8GPUs          70         8         7500  5364.228628   \n",
       "1   34B_8GPUs          34         8         7500  2930.255841   \n",
       "2   13B_8GPUs          13         8         7500  1550.814195   \n",
       "3    7B_8GPUs           7         8         7500  1074.694161   \n",
       "4   34B_4GPUs          34         4         7500  2291.938375   \n",
       "5   13B_4GPUs          13         4         7500  1333.532095   \n",
       "6    7B_4GPUs           7         4         7500   936.629993   \n",
       "7    7B_1GPUs           7         1         7500   936.629993   \n",
       "\n",
       "   time_per_prompt  tok_per_sec  total_out_tok  total_in_tok  avg_out_tok  \\\n",
       "0         0.715230   215.326206      1155059.0     1905000.0   154.007867   \n",
       "1         0.390701   334.550651       980319.0     1920000.0   130.709200   \n",
       "2         0.206775   554.112158       859325.0     1920000.0   114.576667   \n",
       "3         0.143293   921.779456       990631.0     1920000.0   132.084133   \n",
       "4         0.305592   427.230073       979185.0     1920000.0   130.558000   \n",
       "5         0.177804   648.803282       865200.0     1920000.0   115.360000   \n",
       "6         0.124884  1057.411152       990403.0     1920000.0   132.053733   \n",
       "7         0.124884  1057.411152       990403.0     1920000.0   132.053733   \n",
       "\n",
       "   avg_in_tok  emissions_per_1M_prompts  total_energy_per_1M_prompts  \\\n",
       "0       254.0                115.968001                   174.401537   \n",
       "1       256.0                 60.124206                    90.419374   \n",
       "2       256.0                 31.845256                    47.891329   \n",
       "3       256.0                 21.879479                    32.904032   \n",
       "4       256.0                 25.314835                    38.070383   \n",
       "5       256.0                 14.795574                    22.250715   \n",
       "6       256.0                 10.085866                    15.167895   \n",
       "7       256.0                 10.085866                    15.167895   \n",
       "\n",
       "   cpu_energy_per_1M_prompts  gpu_energy_per_1M_prompts  \\\n",
       "0                  10.301362                  98.036465   \n",
       "1                   5.627253                  48.702914   \n",
       "2                   2.978204                  25.817401   \n",
       "3                   2.063889                  17.602871   \n",
       "4                   4.401405                  26.617137   \n",
       "5                   2.560907                  15.586729   \n",
       "6                   1.798727                  10.487412   \n",
       "7                   1.798727                  10.487412   \n",
       "\n",
       "   ram_energy_per_1M_prompts  idle_gpu_energy_per_1M_prompts  \\\n",
       "0                  66.063711                       44.503230   \n",
       "1                  36.089207                       24.310271   \n",
       "2                  19.095723                       12.866014   \n",
       "3                  13.237272                        8.915981   \n",
       "4                   7.051840                        9.507300   \n",
       "5                   4.103079                        5.531689   \n",
       "6                   2.881756                        3.885280   \n",
       "7                   2.881756                        0.971320   \n",
       "\n",
       "   non_idle_gpu_energy_per_1M_prompts  \n",
       "0                           53.533235  \n",
       "1                           24.392643  \n",
       "2                           12.951387  \n",
       "3                            8.686889  \n",
       "4                           17.109837  \n",
       "5                           10.055040  \n",
       "6                            6.602132  \n",
       "7                            9.516092  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframe\n",
    "df = pd.DataFrame({\n",
    "    'model_setup': setup,\n",
    "    'parameters': parameters,\n",
    "    'num_gpus': num_gpus,\n",
    "    'num_prompts': num_prompts,\n",
    "    'total_time': total_time,\n",
    "    'time_per_prompt': time_per_prompt,\n",
    "    'tok_per_sec': tok_per_sec,\n",
    "    'total_out_tok': total_output_tokens,\n",
    "    'total_in_tok': total_input_tokens,\n",
    "    'avg_out_tok': avg_output_tokens,\n",
    "    'avg_in_tok': avg_input_tokens,\n",
    "    'emissions_per_1M_prompts': emissions_per_million_prompts['Total Emissions'],\n",
    "    'total_energy_per_1M_prompts': emissions_per_million_prompts['Total Energy'],\n",
    "    'cpu_energy_per_1M_prompts': emissions_per_million_prompts['CPU Energy'],\n",
    "    'gpu_energy_per_1M_prompts': emissions_per_million_prompts['GPU Energy'],\n",
    "    'ram_energy_per_1M_prompts': emissions_per_million_prompts['RAM Energy'],\n",
    "    'idle_gpu_energy_per_1M_prompts': emissions_per_million_prompts['GPU Energy (idle)'],\n",
    "    'non_idle_gpu_energy_per_1M_prompts': emissions_per_million_prompts['GPU Energy (without idle)'],\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the results in a CSV file\n",
    "df.to_csv('results/data/params_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
