{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the individual CSV files\n",
    "csv_files = {\n",
    "    '1': 'meta-llama/Meta-Llama-3-8B-Instruct-emissiondata-1-examples.csv',\n",
    "    '5': 'meta-llama/Meta-Llama-3-8B-Instruct-emissiondata-5-examples.csv',\n",
    "    '10': 'meta-llama/Meta-Llama-3-8B-Instruct-emissiondata-10-examples.csv',\n",
    "    '20': 'meta-llama/Meta-Llama-3-8B-Instruct-emissiondata-20-examples.csv',\n",
    "    '30': 'meta-llama/Meta-Llama-3-8B-Instruct-emissiondata-30-examples.csv',\n",
    "    '70': 'meta-llama/Meta-Llama-3-8B-Instruct-emissiondata-70-examples.csv',\n",
    "    '210': 'meta-llama/Meta-Llama-3-8B-Instruct-emissiondata-210-examples.csv',\n",
    "    '350': 'meta-llama/Meta-Llama-3-8B-Instruct-emissiondata-350-examples.csv',\n",
    "}\n",
    "\n",
    "# Read the emissions data\n",
    "emissions_data = pd.read_csv('emissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store metadata\n",
    "parameters = []\n",
    "num_examples = []\n",
    "total_emissions = []\n",
    "cpu_energy = []\n",
    "gpu_energy = []\n",
    "ram_energy = []\n",
    "total_output_tokens = []\n",
    "total_input_tokens = []\n",
    "avg_input_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and extract metadata from each CSV file\n",
    "for model, file in csv_files.items():\n",
    "    data = pd.read_csv(file)\n",
    "    output_tokens = data.loc[data['Metric'] == 'Total Output Tokens', 'Value'].values[0]\n",
    "    input_tokens = data.loc[data['Metric'] == 'Total Input Tokens', 'Value'].values[0]\n",
    "    avg_i_tok = data.loc[data['Metric'] == 'Avg Input Tokens per Prompt', 'Value'].values[0]\n",
    "    parameters.append(70)\n",
    "    num_examples.append(int(model))\n",
    "    total_output_tokens.append(float(output_tokens))\n",
    "    total_input_tokens.append(float(input_tokens))\n",
    "    avg_input_tokens.append(float(avg_i_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract emissions data\n",
    "for model in csv_files.keys():\n",
    "    model_emissions = emissions_data[emissions_data['project_name'].str.contains(\"8B-Instruct-emissiondata-\" + model + \"-\")]\n",
    "    total_emissions.append(model_emissions['emissions'].values[0])\n",
    "    cpu_energy.append(model_emissions['cpu_energy'].values[0])\n",
    "    gpu_energy.append(model_emissions['gpu_energy'].values[0])\n",
    "    ram_energy.append(model_emissions['ram_energy'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2701.0, 2706.0, 2691.0, 2707.0, 2705.0, 2736.0, 2777.0, 2821.0]\n",
      "[0.0199979467296797, 0.0203268454993705, 0.0205117219125248, 0.0211612903588763, 0.021899838445093, 0.0248178578752835, 0.0364961148272292, 0.0511827769119716]\n"
     ]
    }
   ],
   "source": [
    "print(total_output_tokens)\n",
    "print(total_emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for regression and visualization\n",
    "parameters = np.array(parameters)\n",
    "num_examples = np.array(num_examples)\n",
    "total_output_tokens = np.array(total_output_tokens)\n",
    "total_input_tokens = np.array(total_input_tokens)\n",
    "avg_input_tokens = np.array(avg_input_tokens)\n",
    "total_emissions = np.array(total_emissions)\n",
    "cpu_energy = np.array(cpu_energy)\n",
    "gpu_energy = np.array(gpu_energy)\n",
    "ram_energy = np.array(ram_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate emissions per 1,000,000 output tokens\n",
    "emissions_per_million_output_tokens = {\n",
    "    'Total Emissions': total_emissions / total_output_tokens * 1_000_000,\n",
    "    'CPU Energy': cpu_energy / total_output_tokens * 1_000_000,\n",
    "    'GPU Energy': gpu_energy / total_output_tokens * 1_000_000,\n",
    "    'RAM Energy': ram_energy / total_output_tokens * 1_000_000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform regression analysis\n",
    "def perform_regression(x, y):\n",
    "    x = x.reshape(-1, 1)\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    predicted = model.predict(x)\n",
    "    return model, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Emissions - Intercept: 6.982023176464173, Coefficient: 0.001764938846279883\n",
      "CPU Energy - Intercept: 1.8107571471319526, Coefficient: 0.00039545527961131003\n",
      "GPU Energy - Intercept: 5.787662062686252, Coefficient: 0.0016251565814090578\n",
      "RAM Energy - Intercept: 2.9016805480915053, Coefficient: 0.0006336379866482673\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "predictions = {}\n",
    "for name, y in emissions_per_million_output_tokens.items():\n",
    "    model, predicted = perform_regression(avg_input_tokens, y)\n",
    "    models[name] = model\n",
    "    predictions[name] = predicted\n",
    "    print(f\"{name} - Intercept: {model.intercept_}, Coefficient: {model.coef_[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Altair visualization\n",
    "vis_data = pd.DataFrame({\n",
    "    'Parameters (billions)': parameters.flatten(),\n",
    "    'Number of Examples': num_examples.flatten(),\n",
    "    'Total Output Tokens': total_output_tokens.flatten(),\n",
    "    'Total Input Tokens': total_input_tokens.flatten(),\n",
    "    'Avg Input Tokens per Prompt': avg_input_tokens.flatten(),\n",
    "    'Total Emissions per Million Output Tokens': emissions_per_million_output_tokens['Total Emissions'],\n",
    "    'CPU Energy per Million Output Tokens': emissions_per_million_output_tokens['CPU Energy'],\n",
    "    'GPU Energy per Million Output Tokens': emissions_per_million_output_tokens['GPU Energy'],\n",
    "    'RAM Energy per Million Output Tokens': emissions_per_million_output_tokens['RAM Energy'],\n",
    "    'Total Emissions Predicted': predictions['Total Emissions'],\n",
    "    'CPU Energy Predicted': predictions['CPU Energy'],\n",
    "    'GPU Energy Predicted': predictions['GPU Energy'],\n",
    "    'RAM Energy Predicted': predictions['RAM Energy']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d94eea933e4841e6b57cc9007fe65ae7.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d94eea933e4841e6b57cc9007fe65ae7.vega-embed details,\n",
       "  #altair-viz-d94eea933e4841e6b57cc9007fe65ae7.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d94eea933e4841e6b57cc9007fe65ae7\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d94eea933e4841e6b57cc9007fe65ae7\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d94eea933e4841e6b57cc9007fe65ae7\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"blue\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"Total Emissions per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Total Emissions per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual Total Emissions per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"blue\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"Total Emissions per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Total Emissions Predicted\", \"type\": \"quantitative\"}}}], \"height\": 350, \"width\": 600}, {\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"green\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"CPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"CPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual CPU Energy per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"green\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"CPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"CPU Energy Predicted\", \"type\": \"quantitative\"}}}], \"height\": 350, \"width\": 600}]}, {\"hconcat\": [{\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"red\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"GPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"GPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual GPU Energy per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"red\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"GPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"GPU Energy Predicted\", \"type\": \"quantitative\"}}}], \"height\": 350, \"width\": 600}, {\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"purple\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"RAM Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"RAM Energy per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual RAM Energy per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"purple\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"RAM Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"RAM Energy Predicted\", \"type\": \"quantitative\"}}}], \"height\": 350, \"width\": 600}]}], \"data\": {\"name\": \"data-a0c1f67c85578429d5db902198c646c1\"}, \"resolve\": {\"scale\": {\"y\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-a0c1f67c85578429d5db902198c646c1\": [{\"Parameters (billions)\": 70, \"Number of Examples\": 1, \"Total Output Tokens\": 2701.0, \"Total Input Tokens\": 23799.0, \"Avg Input Tokens per Prompt\": 158.66, \"Total Emissions per Million Output Tokens\": 7.403904749973973, \"CPU Energy per Million Output Tokens\": 1.9400769738625325, \"GPU Energy per Million Output Tokens\": 6.0857259903836365, \"RAM Energy per Million Output Tokens\": 3.1087545283226956, \"Total Emissions Predicted\": 7.262048373814939, \"CPU Energy Predicted\": 1.873500081795083, \"GPU Energy Predicted\": 6.045509405892613, \"RAM Energy Predicted\": 3.0022135510531194}, {\"Parameters (billions)\": 70, \"Number of Examples\": 5, \"Total Output Tokens\": 2706.0, \"Total Input Tokens\": 33399.0, \"Avg Input Tokens per Prompt\": 222.66, \"Total Emissions per Million Output Tokens\": 7.511768477224871, \"CPU Energy per Million Output Tokens\": 1.939001822514191, \"GPU Energy per Million Output Tokens\": 6.25056359041153, \"RAM Energy per Million Output Tokens\": 3.107205791595824, \"Total Emissions Predicted\": 7.375004459976852, \"CPU Energy Predicted\": 1.8988092196902069, \"GPU Energy Predicted\": 6.149519427102793, \"RAM Energy Predicted\": 3.0427663821986086}, {\"Parameters (billions)\": 70, \"Number of Examples\": 10, \"Total Output Tokens\": 2691.0, \"Total Input Tokens\": 45249.0, \"Avg Input Tokens per Prompt\": 301.66, \"Total Emissions per Million Output Tokens\": 7.622341847835302, \"CPU Energy per Million Output Tokens\": 1.94907049960301, \"GPU Energy per Million Output Tokens\": 6.390778075994202, \"RAM Energy per Million Output Tokens\": 3.1232113095307694, \"Total Emissions Predicted\": 7.514434628832962, \"CPU Energy Predicted\": 1.9300501867795004, \"GPU Energy Predicted\": 6.277906797034108, \"RAM Energy Predicted\": 3.0928237831438214}, {\"Parameters (billions)\": 70, \"Number of Examples\": 20, \"Total Output Tokens\": 2707.0, \"Total Input Tokens\": 69399.0, \"Avg Input Tokens per Prompt\": 462.66, \"Total Emissions per Million Output Tokens\": 7.817248008450793, \"CPU Energy per Million Output Tokens\": 1.9959551997457337, \"GPU Energy per Million Output Tokens\": 6.561699108896195, \"RAM Energy per Million Output Tokens\": 3.1985203482606575, \"Total Emissions Predicted\": 7.798589783084024, \"CPU Energy Predicted\": 1.9937184867969213, \"GPU Energy Predicted\": 6.539557006640966, \"RAM Energy Predicted\": 3.1948394989941926}, {\"Parameters (billions)\": 70, \"Number of Examples\": 30, \"Total Output Tokens\": 2705.0, \"Total Input Tokens\": 94149.0, \"Avg Input Tokens per Prompt\": 627.66, \"Total Emissions per Million Output Tokens\": 8.096058574895748, \"CPU Energy per Million Output Tokens\": 2.042556449755601, \"GPU Energy per Million Output Tokens\": 6.859896607239223, \"RAM Energy per Million Output Tokens\": 3.2730182260059886, \"Total Emissions Predicted\": 8.089804692720204, \"CPU Energy Predicted\": 2.0589686079327874, \"GPU Energy Predicted\": 6.8077078425734605, \"RAM Energy Predicted\": 3.299389766791157}, {\"Parameters (billions)\": 70, \"Number of Examples\": 70, \"Total Output Tokens\": 2736.0, \"Total Input Tokens\": 201549.0, \"Avg Input Tokens per Prompt\": 1343.66, \"Total Emissions per Million Output Tokens\": 9.070854486580227, \"CPU Energy per Million Output Tokens\": 2.2549403191200663, \"GPU Energy per Million Output Tokens\": 7.772926759272076, \"RAM Energy per Million Output Tokens\": 3.6135767540542765, \"Total Emissions Predicted\": 9.3535009066566, \"CPU Energy Predicted\": 2.3421145881344856, \"GPU Energy Predicted\": 7.971319954862347, \"RAM Energy Predicted\": 3.753074565231316}, {\"Parameters (billions)\": 70, \"Number of Examples\": 210, \"Total Output Tokens\": 2777.0, \"Total Input Tokens\": 561549.0, \"Avg Input Tokens per Prompt\": 3743.66, \"Total Emissions per Million Output Tokens\": 13.14228117653194, \"CPU Energy per Million Output Tokens\": 3.186498684890349, \"GPU Energy per Million Output Tokens\": 11.471800779081708, \"RAM Energy per Million Output Tokens\": 5.106066811014692, \"Total Emissions Predicted\": 13.58935413772832, \"CPU Energy Predicted\": 3.2912072592016295, \"GPU Energy Predicted\": 11.871695750244086, \"RAM Energy Predicted\": 5.2738057331871575}, {\"Parameters (billions)\": 70, \"Number of Examples\": 350, \"Total Output Tokens\": 2821.0, \"Total Input Tokens\": 921549.0, \"Avg Input Tokens per Prompt\": 6143.66, \"Total Emissions per Million Output Tokens\": 18.143487030121094, \"CPU Energy per Million Output Tokens\": 4.320568411107905, \"GPU Energy per Million Output Tokens\": 16.041896818697623, \"RAM Energy per Million Output Tokens\": 6.923096412957462, \"Total Emissions Predicted\": 17.825207368800037, \"CPU Energy Predicted\": 4.240299930268773, \"GPU Energy Predicted\": 15.772071545625824, \"RAM Energy Predicted\": 6.794536901142999}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define chart width and height\n",
    "chart_width = 600\n",
    "chart_height = 350\n",
    "\n",
    "# Create scatter and line plots for each emission type per million output tokens\n",
    "charts = []\n",
    "for emission_type, color in zip(['Total Emissions', 'CPU Energy', 'GPU Energy', 'RAM Energy'],\n",
    "                                ['blue', 'green', 'red', 'purple']):\n",
    "    scatter = alt.Chart(vis_data).mark_circle(size=100, color=color).encode(\n",
    "        x='Avg Input Tokens per Prompt',\n",
    "        y=f'{emission_type} per Million Output Tokens',\n",
    "        tooltip=['Parameters (billions)', \n",
    "                 f'{emission_type} per Million Output Tokens', \n",
    "                 'Avg Input Tokens per Prompt', \n",
    "                 'Number of Examples']\n",
    "    ).properties(\n",
    "        title=f'Actual {emission_type} per Million Output Tokens',\n",
    "        width=chart_width,\n",
    "        height=chart_height\n",
    "    )\n",
    "    \n",
    "    # Create line plots for predicted emissions\n",
    "    line = alt.Chart(vis_data).mark_line(color=color).encode(\n",
    "        x='Avg Input Tokens per Prompt',\n",
    "        y=f'{emission_type} Predicted',\n",
    "        tooltip=['Parameters (billions)', \n",
    "                 f'{emission_type} per Million Output Tokens', \n",
    "                 'Avg Input Tokens per Prompt', \n",
    "                 'Number of Examples']\n",
    "    ).properties(\n",
    "        width=chart_width,\n",
    "        height=chart_height\n",
    "    )\n",
    "    \n",
    "    charts.append(scatter + line)\n",
    "\n",
    "# Arrange the charts in a 2x2 grid\n",
    "grid_chart = alt.vconcat(\n",
    "    alt.hconcat(charts[0], charts[1]),\n",
    "    alt.hconcat(charts[2], charts[3])\n",
    ").resolve_scale(\n",
    "    y='independent'\n",
    ")\n",
    "\n",
    "grid_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-0117a465c73a40a981954dd04a34970a.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-0117a465c73a40a981954dd04a34970a.vega-embed details,\n",
       "  #altair-viz-0117a465c73a40a981954dd04a34970a.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-0117a465c73a40a981954dd04a34970a\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-0117a465c73a40a981954dd04a34970a\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-0117a465c73a40a981954dd04a34970a\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"blue\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"Total Emissions per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Total Emissions per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual Total Emissions per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"blue\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"Total Emissions per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Total Emissions Predicted\", \"type\": \"quantitative\"}}}]}, {\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"green\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"CPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"CPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual CPU Energy per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"green\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"CPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"CPU Energy Predicted\", \"type\": \"quantitative\"}}}]}, {\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"red\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"GPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"GPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual GPU Energy per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"red\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"GPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"GPU Energy Predicted\", \"type\": \"quantitative\"}}}]}, {\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"purple\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"RAM Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"RAM Energy per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual RAM Energy per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"purple\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"RAM Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"RAM Energy Predicted\", \"type\": \"quantitative\"}}}]}], \"data\": {\"name\": \"data-a0c1f67c85578429d5db902198c646c1\"}, \"height\": 400, \"resolve\": {\"scale\": {\"y\": \"independent\"}}, \"title\": \"Emissions per Million Output Tokens by Type vs Avg Input Tokens\", \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-a0c1f67c85578429d5db902198c646c1\": [{\"Parameters (billions)\": 70, \"Number of Examples\": 1, \"Total Output Tokens\": 2701.0, \"Total Input Tokens\": 23799.0, \"Avg Input Tokens per Prompt\": 158.66, \"Total Emissions per Million Output Tokens\": 7.403904749973973, \"CPU Energy per Million Output Tokens\": 1.9400769738625325, \"GPU Energy per Million Output Tokens\": 6.0857259903836365, \"RAM Energy per Million Output Tokens\": 3.1087545283226956, \"Total Emissions Predicted\": 7.262048373814939, \"CPU Energy Predicted\": 1.873500081795083, \"GPU Energy Predicted\": 6.045509405892613, \"RAM Energy Predicted\": 3.0022135510531194}, {\"Parameters (billions)\": 70, \"Number of Examples\": 5, \"Total Output Tokens\": 2706.0, \"Total Input Tokens\": 33399.0, \"Avg Input Tokens per Prompt\": 222.66, \"Total Emissions per Million Output Tokens\": 7.511768477224871, \"CPU Energy per Million Output Tokens\": 1.939001822514191, \"GPU Energy per Million Output Tokens\": 6.25056359041153, \"RAM Energy per Million Output Tokens\": 3.107205791595824, \"Total Emissions Predicted\": 7.375004459976852, \"CPU Energy Predicted\": 1.8988092196902069, \"GPU Energy Predicted\": 6.149519427102793, \"RAM Energy Predicted\": 3.0427663821986086}, {\"Parameters (billions)\": 70, \"Number of Examples\": 10, \"Total Output Tokens\": 2691.0, \"Total Input Tokens\": 45249.0, \"Avg Input Tokens per Prompt\": 301.66, \"Total Emissions per Million Output Tokens\": 7.622341847835302, \"CPU Energy per Million Output Tokens\": 1.94907049960301, \"GPU Energy per Million Output Tokens\": 6.390778075994202, \"RAM Energy per Million Output Tokens\": 3.1232113095307694, \"Total Emissions Predicted\": 7.514434628832962, \"CPU Energy Predicted\": 1.9300501867795004, \"GPU Energy Predicted\": 6.277906797034108, \"RAM Energy Predicted\": 3.0928237831438214}, {\"Parameters (billions)\": 70, \"Number of Examples\": 20, \"Total Output Tokens\": 2707.0, \"Total Input Tokens\": 69399.0, \"Avg Input Tokens per Prompt\": 462.66, \"Total Emissions per Million Output Tokens\": 7.817248008450793, \"CPU Energy per Million Output Tokens\": 1.9959551997457337, \"GPU Energy per Million Output Tokens\": 6.561699108896195, \"RAM Energy per Million Output Tokens\": 3.1985203482606575, \"Total Emissions Predicted\": 7.798589783084024, \"CPU Energy Predicted\": 1.9937184867969213, \"GPU Energy Predicted\": 6.539557006640966, \"RAM Energy Predicted\": 3.1948394989941926}, {\"Parameters (billions)\": 70, \"Number of Examples\": 30, \"Total Output Tokens\": 2705.0, \"Total Input Tokens\": 94149.0, \"Avg Input Tokens per Prompt\": 627.66, \"Total Emissions per Million Output Tokens\": 8.096058574895748, \"CPU Energy per Million Output Tokens\": 2.042556449755601, \"GPU Energy per Million Output Tokens\": 6.859896607239223, \"RAM Energy per Million Output Tokens\": 3.2730182260059886, \"Total Emissions Predicted\": 8.089804692720204, \"CPU Energy Predicted\": 2.0589686079327874, \"GPU Energy Predicted\": 6.8077078425734605, \"RAM Energy Predicted\": 3.299389766791157}, {\"Parameters (billions)\": 70, \"Number of Examples\": 70, \"Total Output Tokens\": 2736.0, \"Total Input Tokens\": 201549.0, \"Avg Input Tokens per Prompt\": 1343.66, \"Total Emissions per Million Output Tokens\": 9.070854486580227, \"CPU Energy per Million Output Tokens\": 2.2549403191200663, \"GPU Energy per Million Output Tokens\": 7.772926759272076, \"RAM Energy per Million Output Tokens\": 3.6135767540542765, \"Total Emissions Predicted\": 9.3535009066566, \"CPU Energy Predicted\": 2.3421145881344856, \"GPU Energy Predicted\": 7.971319954862347, \"RAM Energy Predicted\": 3.753074565231316}, {\"Parameters (billions)\": 70, \"Number of Examples\": 210, \"Total Output Tokens\": 2777.0, \"Total Input Tokens\": 561549.0, \"Avg Input Tokens per Prompt\": 3743.66, \"Total Emissions per Million Output Tokens\": 13.14228117653194, \"CPU Energy per Million Output Tokens\": 3.186498684890349, \"GPU Energy per Million Output Tokens\": 11.471800779081708, \"RAM Energy per Million Output Tokens\": 5.106066811014692, \"Total Emissions Predicted\": 13.58935413772832, \"CPU Energy Predicted\": 3.2912072592016295, \"GPU Energy Predicted\": 11.871695750244086, \"RAM Energy Predicted\": 5.2738057331871575}, {\"Parameters (billions)\": 70, \"Number of Examples\": 350, \"Total Output Tokens\": 2821.0, \"Total Input Tokens\": 921549.0, \"Avg Input Tokens per Prompt\": 6143.66, \"Total Emissions per Million Output Tokens\": 18.143487030121094, \"CPU Energy per Million Output Tokens\": 4.320568411107905, \"GPU Energy per Million Output Tokens\": 16.041896818697623, \"RAM Energy per Million Output Tokens\": 6.923096412957462, \"Total Emissions Predicted\": 17.825207368800037, \"CPU Energy Predicted\": 4.240299930268773, \"GPU Energy Predicted\": 15.772071545625824, \"RAM Energy Predicted\": 6.794536901142999}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a combined chart with overlays for all emission types\n",
    "combined_chart = alt.layer(*charts).resolve_scale(\n",
    "    y='independent'\n",
    ").properties(\n",
    "    title='Emissions per Million Output Tokens by Type vs Avg Input Tokens',\n",
    "    width=600,  # Adjusted width for combined chart\n",
    "    height=400  # Adjusted height for combined chart\n",
    ")\n",
    "\n",
    "combined_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
