{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the individual CSV files\n",
    "csv_files = {\n",
    "    '1': 'meta-llama/Meta-Llama-3-70B-Instruct-emissiondata-1-examples.csv',\n",
    "    '5': 'meta-llama/Meta-Llama-3-70B-Instruct-emissiondata-5-examples.csv',\n",
    "    '10': 'meta-llama/Meta-Llama-3-70B-Instruct-emissiondata-10-examples.csv',\n",
    "    '20': 'meta-llama/Meta-Llama-3-70B-Instruct-emissiondata-20-examples.csv',\n",
    "    '30': 'meta-llama/Meta-Llama-3-70B-Instruct-emissiondata-30-examples.csv',\n",
    "    '70': 'meta-llama/Meta-Llama-3-70B-Instruct-emissiondata-70-examples.csv',\n",
    "    '210': 'meta-llama/Meta-Llama-3-70B-Instruct-emissiondata-210-examples.csv',\n",
    "    #'350': 'meta-llama/Meta-Llama-3-70B-Instruct-emissiondata-350-examples.csv',\n",
    "}\n",
    "\n",
    "# Read the emissions data\n",
    "emissions_data = pd.read_csv('emissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store metadata\n",
    "parameters = []\n",
    "num_examples = []\n",
    "total_emissions = []\n",
    "cpu_energy = []\n",
    "gpu_energy = []\n",
    "ram_energy = []\n",
    "total_output_tokens = []\n",
    "total_input_tokens = []\n",
    "avg_input_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and extract metadata from each CSV file\n",
    "for model, file in csv_files.items():\n",
    "    data = pd.read_csv(file)\n",
    "    output_tokens = data.loc[data['Metric'] == 'Total Output Tokens', 'Value'].values[0]\n",
    "    input_tokens = data.loc[data['Metric'] == 'Total Input Tokens', 'Value'].values[0]\n",
    "    avg_i_tok = data.loc[data['Metric'] == 'Avg Input Tokens per Prompt', 'Value'].values[0]\n",
    "    parameters.append(70)\n",
    "    num_examples.append(int(model))\n",
    "    total_output_tokens.append(float(output_tokens))\n",
    "    total_input_tokens.append(float(input_tokens))\n",
    "    avg_input_tokens.append(float(avg_i_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract emissions data\n",
    "for model in csv_files.keys():\n",
    "    model_emissions = emissions_data[emissions_data['project_name'].str.contains(\"-\" + model + \"-\")]\n",
    "    total_emissions.append(model_emissions['emissions'].values[0])\n",
    "    cpu_energy.append(model_emissions['cpu_energy'].values[0])\n",
    "    gpu_energy.append(model_emissions['gpu_energy'].values[0])\n",
    "    ram_energy.append(model_emissions['ram_energy'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4616.0, 4682.0, 4698.0, 4700.0, 4697.0, 2794.0, 2792.0]\n",
      "[0.1323435935756557, 0.1360749588657581, 0.1384953253939468, 0.1398800012080873, 0.1475511355043816, 0.1031574982469381, 0.1735094312983862]\n"
     ]
    }
   ],
   "source": [
    "print(total_output_tokens)\n",
    "print(total_emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for regression and visualization\n",
    "parameters = np.array(parameters)\n",
    "num_examples = np.array(num_examples)\n",
    "total_output_tokens = np.array(total_output_tokens)\n",
    "total_input_tokens = np.array(total_input_tokens)\n",
    "avg_input_tokens = np.array(avg_input_tokens)\n",
    "total_emissions = np.array(total_emissions)\n",
    "cpu_energy = np.array(cpu_energy)\n",
    "gpu_energy = np.array(gpu_energy)\n",
    "ram_energy = np.array(ram_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate emissions per 1,000,000 output tokens\n",
    "emissions_per_million_output_tokens = {\n",
    "    'Total Emissions': total_emissions / total_output_tokens * 1_000_000,\n",
    "    'CPU Energy': cpu_energy / total_output_tokens * 1_000_000,\n",
    "    'GPU Energy': gpu_energy / total_output_tokens * 1_000_000,\n",
    "    'RAM Energy': ram_energy / total_output_tokens * 1_000_000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform regression analysis\n",
    "def perform_regression(x, y):\n",
    "    x = x.reshape(-1, 1)\n",
    "    model = LinearRegression()\n",
    "    model.fit(x, y)\n",
    "    predicted = model.predict(x)\n",
    "    return model, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Emissions - Intercept: 26.112810834407767, Coefficient: 0.009432540286813338\n",
      "CPU Energy - Intercept: 6.020423615609088, Coefficient: 0.002124529078756784\n",
      "GPU Energy - Intercept: 23.603494744257663, Coefficient: 0.008656294668722557\n",
      "RAM Energy - Intercept: 9.646521137522829, Coefficient: 0.003404550817862514\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "predictions = {}\n",
    "for name, y in emissions_per_million_output_tokens.items():\n",
    "    model, predicted = perform_regression(avg_input_tokens, y)\n",
    "    models[name] = model\n",
    "    predictions[name] = predicted\n",
    "    print(f\"{name} - Intercept: {model.intercept_}, Coefficient: {model.coef_[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Altair visualization\n",
    "vis_data = pd.DataFrame({\n",
    "    'Parameters (billions)': parameters.flatten(),\n",
    "    'Number of Examples': num_examples.flatten(),\n",
    "    'Total Output Tokens': total_output_tokens.flatten(),\n",
    "    'Total Input Tokens': total_input_tokens.flatten(),\n",
    "    'Avg Input Tokens per Prompt': avg_input_tokens.flatten(),\n",
    "    'Total Emissions per Million Output Tokens': emissions_per_million_output_tokens['Total Emissions'],\n",
    "    'CPU Energy per Million Output Tokens': emissions_per_million_output_tokens['CPU Energy'],\n",
    "    'GPU Energy per Million Output Tokens': emissions_per_million_output_tokens['GPU Energy'],\n",
    "    'RAM Energy per Million Output Tokens': emissions_per_million_output_tokens['RAM Energy'],\n",
    "    'Total Emissions Predicted': predictions['Total Emissions'],\n",
    "    'CPU Energy Predicted': predictions['CPU Energy'],\n",
    "    'GPU Energy Predicted': predictions['GPU Energy'],\n",
    "    'RAM Energy Predicted': predictions['RAM Energy']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-7809d7019a9e49229093bf5ee9af4805.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-7809d7019a9e49229093bf5ee9af4805.vega-embed details,\n",
       "  #altair-viz-7809d7019a9e49229093bf5ee9af4805.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-7809d7019a9e49229093bf5ee9af4805\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7809d7019a9e49229093bf5ee9af4805\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7809d7019a9e49229093bf5ee9af4805\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"blue\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"Total Emissions per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Total Emissions per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual Total Emissions per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"blue\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"Total Emissions per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Total Emissions Predicted\", \"type\": \"quantitative\"}}}], \"height\": 350, \"width\": 600}, {\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"green\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"CPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"CPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual CPU Energy per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"green\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"CPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"CPU Energy Predicted\", \"type\": \"quantitative\"}}}], \"height\": 350, \"width\": 600}]}, {\"hconcat\": [{\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"red\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"GPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"GPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual GPU Energy per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"red\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"GPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"GPU Energy Predicted\", \"type\": \"quantitative\"}}}], \"height\": 350, \"width\": 600}, {\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"purple\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"RAM Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"RAM Energy per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual RAM Energy per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"purple\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"RAM Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"RAM Energy Predicted\", \"type\": \"quantitative\"}}}], \"height\": 350, \"width\": 600}]}], \"data\": {\"name\": \"data-bb953e34cd6dae2d8830e811bb5a47ee\"}, \"resolve\": {\"scale\": {\"y\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-bb953e34cd6dae2d8830e811bb5a47ee\": [{\"Parameters (billions)\": 70, \"Number of Examples\": 1, \"Total Output Tokens\": 4616.0, \"Total Input Tokens\": 39415.0, \"Avg Input Tokens per Prompt\": 157.66, \"Total Emissions per Million Output Tokens\": 28.670622525055396, \"CPU Energy per Million Output Tokens\": 6.6822732715260615, \"GPU Energy per Million Output Tokens\": 25.72765120866911, \"RAM Energy per Million Output Tokens\": 10.707147609919302, \"Total Emissions Predicted\": 27.599945136026758, \"CPU Energy Predicted\": 6.355376870165883, \"GPU Energy Predicted\": 24.968246161728462, \"RAM Energy Predicted\": 10.183282619467033}, {\"Parameters (billions)\": 70, \"Number of Examples\": 5, \"Total Output Tokens\": 4682.0, \"Total Input Tokens\": 55415.0, \"Avg Input Tokens per Prompt\": 221.66, \"Total Emissions per Million Output Tokens\": 29.063425644117494, \"CPU Energy per Million Output Tokens\": 6.68830161440598, \"GPU Energy per Million Output Tokens\": 26.30260073497751, \"RAM Energy per Million Output Tokens\": 10.71689707450346, \"Total Emissions Predicted\": 28.20362771438281, \"CPU Energy Predicted\": 6.491346731206317, \"GPU Energy Predicted\": 25.522249020526704, \"RAM Energy Predicted\": 10.401173871810233}, {\"Parameters (billions)\": 70, \"Number of Examples\": 10, \"Total Output Tokens\": 4698.0, \"Total Input Tokens\": 75165.0, \"Avg Input Tokens per Prompt\": 300.66, \"Total Emissions per Million Output Tokens\": 29.479635034897147, \"CPU Energy per Million Output Tokens\": 6.718764832726224, \"GPU Energy per Million Output Tokens\": 26.849476825810875, \"RAM Energy per Million Output Tokens\": 10.765485238363198, \"Total Emissions Predicted\": 28.948798397041067, \"CPU Energy Predicted\": 6.659184528428103, \"GPU Energy Predicted\": 26.20609629935579, \"RAM Energy Predicted\": 10.670133386421373}, {\"Parameters (billions)\": 70, \"Number of Examples\": 20, \"Total Output Tokens\": 4700.0, \"Total Input Tokens\": 115415.0, \"Avg Input Tokens per Prompt\": 461.66, \"Total Emissions per Million Output Tokens\": 29.761702384699426, \"CPU Energy per Million Output Tokens\": 6.902573797794384, \"GPU Energy per Million Output Tokens\": 26.79498988041919, \"RAM Energy per Million Output Tokens\": 11.060357644359362, \"Total Emissions Predicted\": 30.467437383218012, \"CPU Energy Predicted\": 7.001233710107945, \"GPU Energy Predicted\": 27.59975974102012, \"RAM Energy Predicted\": 11.218266068097236}, {\"Parameters (billions)\": 70, \"Number of Examples\": 30, \"Total Output Tokens\": 4697.0, \"Total Input Tokens\": 156665.0, \"Avg Input Tokens per Prompt\": 626.66, \"Total Emissions per Million Output Tokens\": 31.413910049900277, \"CPU Energy per Million Output Tokens\": 7.14383523022112, \"GPU Energy per Million Output Tokens\": 28.65189391716779, \"RAM Energy per Million Output Tokens\": 11.446908262044325, \"Total Emissions Predicted\": 32.02380653054222, \"CPU Energy Predicted\": 7.351781008102814, \"GPU Energy Predicted\": 29.02804836135934, \"RAM Energy Predicted\": 11.780016953044552}, {\"Parameters (billions)\": 70, \"Number of Examples\": 70, \"Total Output Tokens\": 2794.0, \"Total Input Tokens\": 201549.0, \"Avg Input Tokens per Prompt\": 1343.66, \"Total Emissions per Million Output Tokens\": 36.92108026017827, \"CPU Energy per Million Output Tokens\": 8.41711345768189, \"GPU Energy per Million Output Tokens\": 33.620838178761524, \"RAM Energy per Million Output Tokens\": 13.486788987232105, \"Total Emissions Predicted\": 38.78693791618738, \"CPU Energy Predicted\": 8.875068357571429, \"GPU Energy Predicted\": 35.234611638833414, \"RAM Energy Predicted\": 14.221079889451975}, {\"Parameters (billions)\": 70, \"Number of Examples\": 210, \"Total Output Tokens\": 2792.0, \"Total Input Tokens\": 561549.0, \"Avg Input Tokens per Prompt\": 3743.66, \"Total Emissions per Million Output Tokens\": 62.14521178308961, \"CPU Energy per Million Output Tokens\": 14.155067147814544, \"GPU Energy per Million Output Tokens\": 56.621279320785355, \"RAM Energy per Million Output Tokens\": 22.682369824192655, \"Total Emissions Predicted\": 61.42503460453939, \"CPU Energy Predicted\": 13.97393814658771, \"GPU Energy Predicted\": 56.009718843767544, \"RAM Energy Predicted\": 22.392001852322007}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define chart width and height\n",
    "chart_width = 600\n",
    "chart_height = 350\n",
    "\n",
    "# Create scatter and line plots for each emission type per million output tokens\n",
    "charts = []\n",
    "for emission_type, color in zip(['Total Emissions', 'CPU Energy', 'GPU Energy', 'RAM Energy'],\n",
    "                                ['blue', 'green', 'red', 'purple']):\n",
    "    scatter = alt.Chart(vis_data).mark_circle(size=100, color=color).encode(\n",
    "        x='Avg Input Tokens per Prompt',\n",
    "        y=f'{emission_type} per Million Output Tokens',\n",
    "        tooltip=['Parameters (billions)', \n",
    "                 f'{emission_type} per Million Output Tokens', \n",
    "                 'Avg Input Tokens per Prompt', \n",
    "                 'Number of Examples']\n",
    "    ).properties(\n",
    "        title=f'Actual {emission_type} per Million Output Tokens',\n",
    "        width=chart_width,\n",
    "        height=chart_height\n",
    "    )\n",
    "    \n",
    "    # Create line plots for predicted emissions\n",
    "    line = alt.Chart(vis_data).mark_line(color=color).encode(\n",
    "        x='Avg Input Tokens per Prompt',\n",
    "        y=f'{emission_type} Predicted',\n",
    "        tooltip=['Parameters (billions)', \n",
    "                 f'{emission_type} per Million Output Tokens', \n",
    "                 'Avg Input Tokens per Prompt', \n",
    "                 'Number of Examples']\n",
    "    ).properties(\n",
    "        width=chart_width,\n",
    "        height=chart_height\n",
    "    )\n",
    "    \n",
    "    charts.append(scatter + line)\n",
    "\n",
    "# Arrange the charts in a 2x2 grid\n",
    "grid_chart = alt.vconcat(\n",
    "    alt.hconcat(charts[0], charts[1]),\n",
    "    alt.hconcat(charts[2], charts[3])\n",
    ").resolve_scale(\n",
    "    y='independent'\n",
    ")\n",
    "\n",
    "grid_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-7f4ef214262740afa26e8fed57b22456.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-7f4ef214262740afa26e8fed57b22456.vega-embed details,\n",
       "  #altair-viz-7f4ef214262740afa26e8fed57b22456.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-7f4ef214262740afa26e8fed57b22456\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7f4ef214262740afa26e8fed57b22456\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7f4ef214262740afa26e8fed57b22456\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"blue\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"Total Emissions per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Total Emissions per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual Total Emissions per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"blue\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"Total Emissions per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Total Emissions Predicted\", \"type\": \"quantitative\"}}}]}, {\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"green\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"CPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"CPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual CPU Energy per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"green\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"CPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"CPU Energy Predicted\", \"type\": \"quantitative\"}}}]}, {\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"red\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"GPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"GPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual GPU Energy per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"red\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"GPU Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"GPU Energy Predicted\", \"type\": \"quantitative\"}}}]}, {\"layer\": [{\"mark\": {\"type\": \"circle\", \"color\": \"purple\", \"size\": 100}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"RAM Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"RAM Energy per Million Output Tokens\", \"type\": \"quantitative\"}}, \"title\": \"Actual RAM Energy per Million Output Tokens\"}, {\"mark\": {\"type\": \"line\", \"color\": \"purple\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Parameters (billions)\", \"type\": \"quantitative\"}, {\"field\": \"RAM Energy per Million Output Tokens\", \"type\": \"quantitative\"}, {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, {\"field\": \"Number of Examples\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Avg Input Tokens per Prompt\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"RAM Energy Predicted\", \"type\": \"quantitative\"}}}]}], \"data\": {\"name\": \"data-bb953e34cd6dae2d8830e811bb5a47ee\"}, \"height\": 400, \"resolve\": {\"scale\": {\"y\": \"independent\"}}, \"title\": \"Emissions per Million Output Tokens by Type vs Avg Input Tokens\", \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-bb953e34cd6dae2d8830e811bb5a47ee\": [{\"Parameters (billions)\": 70, \"Number of Examples\": 1, \"Total Output Tokens\": 4616.0, \"Total Input Tokens\": 39415.0, \"Avg Input Tokens per Prompt\": 157.66, \"Total Emissions per Million Output Tokens\": 28.670622525055396, \"CPU Energy per Million Output Tokens\": 6.6822732715260615, \"GPU Energy per Million Output Tokens\": 25.72765120866911, \"RAM Energy per Million Output Tokens\": 10.707147609919302, \"Total Emissions Predicted\": 27.599945136026758, \"CPU Energy Predicted\": 6.355376870165883, \"GPU Energy Predicted\": 24.968246161728462, \"RAM Energy Predicted\": 10.183282619467033}, {\"Parameters (billions)\": 70, \"Number of Examples\": 5, \"Total Output Tokens\": 4682.0, \"Total Input Tokens\": 55415.0, \"Avg Input Tokens per Prompt\": 221.66, \"Total Emissions per Million Output Tokens\": 29.063425644117494, \"CPU Energy per Million Output Tokens\": 6.68830161440598, \"GPU Energy per Million Output Tokens\": 26.30260073497751, \"RAM Energy per Million Output Tokens\": 10.71689707450346, \"Total Emissions Predicted\": 28.20362771438281, \"CPU Energy Predicted\": 6.491346731206317, \"GPU Energy Predicted\": 25.522249020526704, \"RAM Energy Predicted\": 10.401173871810233}, {\"Parameters (billions)\": 70, \"Number of Examples\": 10, \"Total Output Tokens\": 4698.0, \"Total Input Tokens\": 75165.0, \"Avg Input Tokens per Prompt\": 300.66, \"Total Emissions per Million Output Tokens\": 29.479635034897147, \"CPU Energy per Million Output Tokens\": 6.718764832726224, \"GPU Energy per Million Output Tokens\": 26.849476825810875, \"RAM Energy per Million Output Tokens\": 10.765485238363198, \"Total Emissions Predicted\": 28.948798397041067, \"CPU Energy Predicted\": 6.659184528428103, \"GPU Energy Predicted\": 26.20609629935579, \"RAM Energy Predicted\": 10.670133386421373}, {\"Parameters (billions)\": 70, \"Number of Examples\": 20, \"Total Output Tokens\": 4700.0, \"Total Input Tokens\": 115415.0, \"Avg Input Tokens per Prompt\": 461.66, \"Total Emissions per Million Output Tokens\": 29.761702384699426, \"CPU Energy per Million Output Tokens\": 6.902573797794384, \"GPU Energy per Million Output Tokens\": 26.79498988041919, \"RAM Energy per Million Output Tokens\": 11.060357644359362, \"Total Emissions Predicted\": 30.467437383218012, \"CPU Energy Predicted\": 7.001233710107945, \"GPU Energy Predicted\": 27.59975974102012, \"RAM Energy Predicted\": 11.218266068097236}, {\"Parameters (billions)\": 70, \"Number of Examples\": 30, \"Total Output Tokens\": 4697.0, \"Total Input Tokens\": 156665.0, \"Avg Input Tokens per Prompt\": 626.66, \"Total Emissions per Million Output Tokens\": 31.413910049900277, \"CPU Energy per Million Output Tokens\": 7.14383523022112, \"GPU Energy per Million Output Tokens\": 28.65189391716779, \"RAM Energy per Million Output Tokens\": 11.446908262044325, \"Total Emissions Predicted\": 32.02380653054222, \"CPU Energy Predicted\": 7.351781008102814, \"GPU Energy Predicted\": 29.02804836135934, \"RAM Energy Predicted\": 11.780016953044552}, {\"Parameters (billions)\": 70, \"Number of Examples\": 70, \"Total Output Tokens\": 2794.0, \"Total Input Tokens\": 201549.0, \"Avg Input Tokens per Prompt\": 1343.66, \"Total Emissions per Million Output Tokens\": 36.92108026017827, \"CPU Energy per Million Output Tokens\": 8.41711345768189, \"GPU Energy per Million Output Tokens\": 33.620838178761524, \"RAM Energy per Million Output Tokens\": 13.486788987232105, \"Total Emissions Predicted\": 38.78693791618738, \"CPU Energy Predicted\": 8.875068357571429, \"GPU Energy Predicted\": 35.234611638833414, \"RAM Energy Predicted\": 14.221079889451975}, {\"Parameters (billions)\": 70, \"Number of Examples\": 210, \"Total Output Tokens\": 2792.0, \"Total Input Tokens\": 561549.0, \"Avg Input Tokens per Prompt\": 3743.66, \"Total Emissions per Million Output Tokens\": 62.14521178308961, \"CPU Energy per Million Output Tokens\": 14.155067147814544, \"GPU Energy per Million Output Tokens\": 56.621279320785355, \"RAM Energy per Million Output Tokens\": 22.682369824192655, \"Total Emissions Predicted\": 61.42503460453939, \"CPU Energy Predicted\": 13.97393814658771, \"GPU Energy Predicted\": 56.009718843767544, \"RAM Energy Predicted\": 22.392001852322007}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a combined chart with overlays for all emission types\n",
    "combined_chart = alt.layer(*charts).resolve_scale(\n",
    "    y='independent'\n",
    ").properties(\n",
    "    title='Emissions per Million Output Tokens by Type vs Avg Input Tokens',\n",
    "    width=600,  # Adjusted width for combined chart\n",
    "    height=400  # Adjusted height for combined chart\n",
    ")\n",
    "\n",
    "combined_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
