{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8230136,"sourceType":"datasetVersion","datasetId":4880117},{"sourceId":33547,"sourceType":"modelInstanceVersion","modelInstanceId":28079}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install trl numpy peft transformers datasets bitsandbytes huggingface_hub tqdm","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-05-28T09:17:47.079062Z","iopub.execute_input":"2024-05-28T09:17:47.079845Z","iopub.status.idle":"2024-05-28T09:18:06.359040Z","shell.execute_reply.started":"2024-05-28T09:17:47.079817Z","shell.execute_reply":"2024-05-28T09:18:06.357850Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting trl\n  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nCollecting peft\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.22.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.1.2)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl) (0.29.3)\nCollecting tyro>=0.5.11 (from trl)\n  Downloading tyro-0.8.4-py3-none-any.whl.metadata (7.9 kB)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.2)\nRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.15)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.0)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\nDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.8.4-py3-none-any.whl (102 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, tyro, bitsandbytes, trl, peft\nSuccessfully installed bitsandbytes-0.43.1 peft-0.11.1 shtab-1.7.1 trl-0.8.6 tyro-0.8.4\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nfrom datasets import load_dataset, Dataset\nfrom scipy.special import softmax\nfrom peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\nfrom sklearn.metrics import accuracy_score, f1_score, log_loss, confusion_matrix\nfrom transformers import pipeline, set_seed, TrainingArguments, Trainer, AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig, DataCollatorWithPadding\nfrom huggingface_hub import notebook_login, login\nimport json\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport random","metadata":{"execution":{"iopub.status.busy":"2024-05-28T09:18:06.361620Z","iopub.execute_input":"2024-05-28T09:18:06.362310Z","iopub.status.idle":"2024-05-28T09:18:18.527421Z","shell.execute_reply.started":"2024-05-28T09:18:06.362279Z","shell.execute_reply":"2024-05-28T09:18:18.526677Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-05-28 09:18:11.307132: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-28 09:18:11.307255: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-28 09:18:11.398702: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"#model_name = 'meta-llama/Meta-Llama-3-8B'\n#model_name = 'meta-llama/Llama-2-7b-hf'\nmodel_name = 'meta-llama/Llama-2-13b-hf'\n#model_name = 'meta-llama/Llama-2-70b-hf'\n#model_path = \"/kaggle/input/llama-3/transformers/8b-hf/1\"\n\n#model_name = \"unsloth/llama-3-70b-bnb-4bit\"\n\n#save_path = f\"models/{model_name}\"\n#print(f\"Saving model to / Loading model from:\\n\\n -> {save_path}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-28T09:18:18.528601Z","iopub.execute_input":"2024-05-28T09:18:18.530707Z","iopub.status.idle":"2024-05-28T09:18:18.535696Z","shell.execute_reply.started":"2024-05-28T09:18:18.530654Z","shell.execute_reply":"2024-05-28T09:18:18.534727Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#quantization configurations - so you quantize the model while inferencing\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    #bnb_4bit_qunat_type = \"nf4\",\n    bnb_4bit_compute_dtype = torch.float16,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T09:18:18.537176Z","iopub.execute_input":"2024-05-28T09:18:18.537745Z","iopub.status.idle":"2024-05-28T09:18:18.561456Z","shell.execute_reply.started":"2024-05-28T09:18:18.537713Z","shell.execute_reply":"2024-05-28T09:18:18.560340Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"login()","metadata":{"execution":{"iopub.status.busy":"2024-05-28T09:18:18.563745Z","iopub.execute_input":"2024-05-28T09:18:18.564363Z","iopub.status.idle":"2024-05-28T09:18:18.591389Z","shell.execute_reply.started":"2024-05-28T09:18:18.564324Z","shell.execute_reply":"2024-05-28T09:18:18.590151Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b98a0daa10f549c6947d3ff4c1386522"}},"metadata":{}}]},{"cell_type":"code","source":"# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.bos_token\n\n# Load the model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    #model_path,\n    num_labels=4,  # Adjust if necessary based on the specific task\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    #device_map=device_map,\n    #load_in_8bit_fp32_cpu_offload=True,\n)\nmodel.config.pad_token_id = tokenizer.pad_token_id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test the Model","metadata":{}},{"cell_type":"code","source":"# Load the HellaSwag dataset\ndataset = load_dataset('hellaswag', trust_remote_code=True)\n\n# Print the structure of the dataset\nprint(dataset['train'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sample 10-shot examples from the training set\ntrain_examples = random.sample(list(dataset['train']), 10)\n\n# Sample 500 questions from the validation set\ntest_questions = random.sample(list(dataset['validation']), 25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to create system prompt for the model with 10-shot examples\ndef create_inputs(ten_shot_examples, test_example):\n    \"\"\"\n    Combines 10-shot examples with the test example to create input texts in Meta Llama 2 format.\n    \"\"\"\n    \n    examples = \"\"\n    task = \"\"\n\n    examples += \"10-Shot Examples for guidance:\\n\" + \"=\"*25\n    for idx, example in enumerate(ten_shot_examples):\n        examples += f\"\\n Example {idx}:\\n\"\n        examples += f\"Context: {example['ctx']}\\n\"\n        examples += f\"Options:\\n\"\n        for i, ending in enumerate(example['endings']):\n            examples += f\"Option {i}: {ending}\\n\\n\"\n        examples += f\"Correct Answer: Option {int(example['label'])}\\n\"\n        examples += \"-\"*25\n    \n    task += f\"\\n Task:\\n\"\n    task += f\"Context: {test_example['ctx']}\\n\"\n    task += f\"Options:\\n\"\n    for i, ending in enumerate(test_example['endings']):\n        task += f\"Option {i}: {ending}\\n\\n\"\n    task += f\"Correct Answer:\"\n\n    \n\n\n    # Define the system prompt\n    prompt = (\n        f\"\"\"\n        [INST] <<SYS>>\n        You are an advanced AI model with the task to solve a multiple-choice test called 'HellaSwag'.\\n\n        You will be provided with a context and four possible endings. Your task is to predict the correct ending.\\n\n        As a guidance you will be provided with 20 examples of the task before you start the test.\\n\n        These are the examples:\\n\\n\n        {examples}\n        \\n\\n\n        With these examples in mind, select the option that most likely ends the following context: \\n\n        <</SYS>>\n        {task} \\n\n        [/INST]\n        \"\"\"\n    )\n\n\n    return prompt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to print the 10-shot examples\ndef print_ten_shot_examples(ten_shot_examples):\n    print(\"10-Shot Examples added into the System Prompt:\\n\" + \"=\"*50)\n    for idx, example in enumerate(ten_shot_examples[:2]):  # Only print the first two examples\n        print(f\"Example {idx + 1}:\")\n        print(f\"Context: {example['ctx']}\\n\")\n        for i, ending in enumerate(example['endings']):\n            print(f\"Option {i + 1}: {ending}\\n\")\n        print(f\"Correct Answer: Option {int(example['label']) + 1}\\n\")\n        print(\"-\" * 50)\n    print(\"[...]\\n\" + \"=\"*50)  # Indicate that there are more examples","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the 10-shot examples once\nprint_ten_shot_examples(train_examples)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to evaluate the model on the test set and print details\ndef evaluate_model(test_set, ten_shot_examples, model, tokenizer):\n    \"\"\"\n    Evaluates the model on a set of test examples, printing details every 25 examples.\n    \"\"\"\n    correct_count = 0\n    total_count = len(test_set)\n\n    # Add a loading bar\n    for idx, test_example in enumerate(tqdm(test_set, desc=\"Evaluating\", unit=\"example\")):\n        \n        input_text = create_inputs(ten_shot_examples, test_example)\n        # Tokenize the input text\n        inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n\n        outputs = model(**inputs)\n        \n        logits = outputs.logits.to(torch.float32)  # Cast logits to float32\n        probabilities = torch.softmax(logits, dim=-1)\n        predicted_label = torch.argmax(probabilities, dim=-1).item()\n        confidence = probabilities[0][predicted_class].item()\n        \n        #print(input_texts)\n        \n        print(f\"Example {i + 1}:\\n{input_texts}\\n\")\n        print(f\"Predicted Class: {chr(65 + predicted_label)} with confidence {confidence:.2f}\\n\")\n        print(f\"Correct Answer: {int(test_example['label'])}\\n\")\n        print(\"-\" * 50 + \"\\n\")\n        \n\n        if int(predicted_label) == int(test_example['label']):\n            correct_count += 1\n            #print(\"correct answer\")\n\n        # Print details every 25th example\n        #if (idx + 1) % 25 == 0:\n        #print(f\"Question {idx + 1}: {test_example['ctx']}\")\n        #for i, ending in enumerate(test_example['endings']):\n        #    print(f\"Option {i + 1}: {ending}\")\n        #print(f\"Correct Answer: Option {int(test_example['label']) + 1}\")\n        #print(f\"Model Prediction: Option {predicted_label + 1}\")\n        #print(\"-\" * 50)\n        \n\n    accuracy = correct_count / total_count\n    return accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\naccuracy = evaluate_model(test_questions, train_examples, model, tokenizer)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}